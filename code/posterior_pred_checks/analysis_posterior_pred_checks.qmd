---
title: "Posterior Predictive Checks"
format: 
  html:
    theme:
      light: yeti
      dark: superhero
    fontsize: small
    grid:
      sidebar-width: 15em
    code-fold: true
    toc: true
    toc-location: left
    toc-title: Contents
    toc-depth: 3
    toc-expand: true
    embed-resources: true
    html-math-method: katex
editor: source
---

# Setup

```{r}
library(here)
library(data.table)
library(magrittr)

# Get repo path
base_path = file.path(here::here(),
                      fsep = .Platform$file.sep)

# Source own functions
source_path = file.path(base_path, 'code', fsep = .Platform$file.sep)
source(file.path(source_path, 'utils', 'Load_model_fits_new.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'utils', 'Add_comp.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'utils', 'Get_running_avg.R', fsep = .Platform$file.sep))


# # Load data
# files_pattern = file.path(base_path, 'derivatives', 'posterior_pred_checks', 'postpred-*_model-*.tsv',
#                           fsep = .Platform$file.sep)
# files = Sys.glob(files_pattern)
# data = data.table::data.table()
# for(file in files){
#   temp = data.table::fread(file, sep = '\t', na.strings = 'n/a')
#   data = rbind(data, temp)
# }

# Glob files based on naming pattern
files_pattern = file.path(base_path, 'derivatives', 'posterior_pred_checks', 'postpred-*_model-*.tsv',
                          fsep = .Platform$file.sep)
files = Sys.glob(files_pattern)

# Function to load text files (.tsv)
Load_tsv = function(file_path){
  tsv = data.table::fread(file_path,
                          sep = '\t',
                          na.strings = 'n/a')
  return(tsv)
}

# Get list of all text files using parallel processing
data_list = parallel::mclapply(X = files,
                               FUN = Load_tsv,
                               mc.cores = 4)
# Bind individual list entries (loaded text files) to single data frame
# (using optimized bind function by data.table package)
data = data.table::rbindlist(data_list)
```

# Checks

```{r}
# Load model fitting data to check if correct parameters were used for PPC
data_fitting = Load_model_fits_new()
fit_params = data_fitting %>%
  .[starting_values == 'random',] %>%
  .[variable == 'coefs',] %>%
  # Exclude betas weights based in z-scored predictors (could not be used in
  # data simulation for posterior pred checks)
  .[substr(x, 0, 2) != 'z_', ] %>%
  # Recode beta weight names
  .[x == '(Intercept)', names := 'b0'] %>%
  .[x == 'V1', names := 'b1'] %>%
  .[x == 'V2', names := 'b2'] %>%
  .[x == 'V1u', names := 'b3'] %>%
  .[x == 'V2u', names := 'b4'] %>%
  .[is.na(names), names := paste0('x', seq(.N)),
    by = c('participant_id', 'model')] %>%
  .[, c('participant_id', 'model', 'names', 'value')] %>%
  .[, (c('participant_id', 'model', 'names')) := lapply(.SD, factor), .SDcols = c('participant_id', 'model', 'names')] %>%
  data.table::setnames(old = 'value', new = 'value_fit')

sim_params = data %>%
  .[,.(x1 = unique(x1),
       x2 = unique(x2),
       x3 = unique(x3),
       x4 = unique(x4),
       b0 = unique(b0),
       b1 = unique(b1),
       b2 = unique(b2),
       b3 = unique(b3),
       b4 = unique(b4)),
    by = c('participant_id', 'model')] %>%
  data.table::melt(id.vars = c('participant_id', 'model'),
                   variable.name = 'names') %>%
  .[!is.na(value),] %>%
  data.table::setorder(participant_id, model, names) %>%
  data.table::setnames(old = 'value', new = 'value_sim')

check = data.table::merge.data.table(fit_params,
                                     sim_params,
                                     by = c('participant_id', 'model', 'names')) %>%
  .[, value_fit := round(value_fit, 5)] %>%
  .[, value_sim := round(value_sim, 5)] %>%
  .[, check := value_fit == value_sim]

fails = check[check != TRUE,]
```

# Choice comparison

```{r}
data_choicecomp = data
```

# Value comparison

```{r}
# Load modeldata (from model fitting)
files_pattern = file.path(base_path, 'derivatives', 'model_fitting', 'modeldata-*_sv-random.tsv',
                          fsep = .Platform$file.sep)
files = Sys.glob(files_pattern)

# Get list of all text files using parallel processing
data_list = parallel::mclapply(X = files,
                               FUN = Load_tsv,
                               mc.cores = 4)
# Bind individual list entries (loaded text files) to single data frame
# (using optimized bind function by data.table package)
modeldata_fit = data.table::rbindlist(data_list)

# key columns
cols = c('participant_id', 'model', 'run', 'trial', 'option_left', 
         'option_right', 'is_rare', 'reward_stim_1', 'reward_stim_2', 'trial_type',
         'forced', 'choice', 'option_choice', 'outcome',
         'value_low', 'value_mid', 'value_high')

data_real = modeldata_fit[, ..cols] %>%
  .[, datatype := 'participant']

data_pred = data %>%
  .[, choice := 'left'] %>%
  .[model_choice_side == 2, choice := 'right'] %>%
  .[, ':='(option_choice = model_choice_option,
           outcome = model_outcome,
           value_low = val_b_1,
           value_mid = val_b_2,
           value_high = val_b_3)] %>%
  .[, ..cols] %>%
  .[, datatype := 'prediction']

data_ppc = rbind(data_real, data_pred) %>%
  .[, datatype := factor(datatype)] %>%
  data.table::setorder(participant_id, model, trial, datatype)
```

---

# CBE in predictions

```{r}
# # Make sure we only include choices in 1v2 comps when calculating prob of choosing 2
# data_ii = data_pred %>%
#   Add_comp(.) %>%
#    .[, correct := if(option_left > option_right) 'left' else 'right',
#     by = c('participant_id', 'model', 'run', 'trial')] %>%
#   .[, correct_choice := correct == choice] %>%
#   .[comp != '1v2' | trial_type != 'choice', correct_choice := NA,
#     by = c('participant_id', 'model', 'run')] %>%
#   # Get running averages
#   .[, ':='(avg_1_running = Get_running_avg(choice_option = option_choice,
#                                            choice_outcome = outcome,
#                                            stim = 1),
#            avg_2_running = Get_running_avg(choice_option = option_choice,
#                                            choice_outcome = outcome,
#                                            stim = 2),
#            avg_3_running = Get_running_avg(choice_option = option_choice,
#                                            choice_outcome = outcome,
#                                            stim = 3)),
#     by = c('participant_id', 'model', 'run')]
# 
# # Allocate data holding +-5 trials from rare outcome of bandit 2
# window_data = data.table()
# 
# # Function to get data slice +-5 trials from rare outcome of bandit 2
# Windowrize = function(data,
#                       index_rare,
#                       window_size){
#   result = data[seq(max(index_rare - window_size + 1, 1),
#                     index_rare + window_size), ]
#   result$window_center = data$trial[index_rare]
#   result$window_relative = seq(max(index_rare - window_size + 1, 1),
#                                index_rare + window_size) - index_rare
#   result[window_relative == 0]$correct_choice = NA
# 
#   result$window_center = as.factor(result$window_center)
#   result$window_relative = as.factor(result$window_relative)
#   return(result)
# }
# 
# # i_id = '09RI1ZH'
# # i_model = 'rw'
# # i_run = '1'
# 
# # For each participant, model, & run
# for(i_id in unique(data_ii$participant_id)){
#   for(i_model in unique(data_ii$model)){
#     for(i_run in unique(data_ii$run)){
#       
#       # Select data
#       temp_data = data_ii[participant_id == i_id &
#                             model == i_model &
#                             run == i_run]
#       
#       # Get all trials where rare outcomes were obtained
#       idx_chosen_rare_outcome = which(temp_data$is_rare == 1 &
#                                         # CHANGE: I also allow rare outcomes that came from forced choices
#                                         temp_data$trial_type %in% c('choice', 'forced') &
#                                         temp_data$option_choice == 2)
#       # For each of the rare-outcome trials
#       for(rare_count in seq(1,length(idx_chosen_rare_outcome))){
#         # Get data slice
#         temp = Windowrize(data = temp_data,
#                           index_rare = idx_chosen_rare_outcome[rare_count],
#                           window_size = 2) %>%
#           .[, window_relative := factor(window_relative, levels = unique(sort(window_relative)))]
#         # Add count of the rare outcome
#         temp$i_rare = rare_count
#         # Fuse data for each participant & run
#         window_data = rbind(window_data, temp)
#         
#       }
#     }
#   }
#   message(paste0(i_id, '...'))
# }
# 
# # Summarize data
# window_data_run = window_data %>%
#   # Eliminate windows which extended across trial boundaries (<1 or >240)
#   .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
#   .[!(relative_trial < 1 | relative_trial > 240),] %>%
#   # Sort by relative window
#   .[order(rank(participant_id), rank(model), rank(run), rank(window_relative)),] %>%
#   # Get mean accuracy across all relative window positions (-1 to +2)
#   .[, .(mean_accuracy = mean(correct_choice, na.rm = TRUE),
#         n_data = sum(!is.na(correct_choice))),
#     by = c('participant_id', 'model', 'run', 'window_relative')]

# Load windowrize data
file_pattern = file.path(base_path, 'derivatives', 'posterior_pred_checks', 
                         paste0('windowrizepred-*.tsv'),
                         fsep = .Platform$file.sep)
files = Sys.glob(file_pattern)
window_data_run = data.table::data.table()
for(file in files){
  temp = data.table::fread(file, sep = '\t', na.strings = 'n/a')
  window_data_run = rbind(window_data_run, temp)
}

# Get mean across runs
window_data_participant = window_data_run %>%
  .[, .(accuracy = mean(mean_accuracy, na.rm = TRUE)),
    by = c('participant_id', 'model', 'window_relative')]

# Add group information
groupinfo = modeldata_fit[, .(group = unique(group)),
                          by = c('participant_id')]
window_data_participant = data.table::merge.data.table(window_data_participant,
                                                       groupinfo)

# Get age group specific mean and sd
window_data_group = window_data_participant %>%
  .[, .(mean_accuracy = mean(accuracy, na.rm = TRUE),
        sd_accuracy = sd(accuracy, na.rm = TRUE)),
    by = c('group', 'model', 'window_relative')] %>%
  .[order(rank(group), rank(model), rank(window_relative)),]
```

## Check: Average N of rare outcomes per group

```{r}
# avg_n_rare = window_data %>%
#   # Eliminate windows which extended across trial boundaries (<1 or >240)
#   .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
#   .[!(relative_trial < 1 | relative_trial > 240),] %>%
#   # Get number of rare outcomes collected
#   .[, .(n_rare = max(i_rare)),
#     by = c('participant_id', 'group', 'run')]
# 
# data_plot = Prepare_data_for_plot(avg_n_rare)
# 
# dodge_width = 0.075
# jitter_width = dodge_width/2
# 
# p = ggplot(data = data_plot,
#        aes(x = group,
#            y = n_rare,
#            color = group,
#            fill = group)) +
#   geom_hline(yintercept = 0,
#              size = 0.5) +
#   geom_point(position = position_jitternudge(jitter.width = jitter_width,
#                                              jitter.height = 0,
#                                              nudge.x = dodge_width + jitter_width/2,
#                                              seed = 666),
#              alpha = 0.5) +
#   geom_boxplot(outlier.shape = NA,
#                color = 'black',
#                width = dodge_width/2) +
#   gghalves::geom_half_violin(color = NA,
#                              position = position_nudge(x = -dodge_width)) +
#   stat_summary(fun = 'mean',
#                geom = 'point',
#                na.rm = TRUE,
#                shape = 23,
#                fill = 'white',
#                size = 3,
#                stroke = 0.5) +
#   theme(legend.position = 'none')
# Neurocodify_plot(p)

```
