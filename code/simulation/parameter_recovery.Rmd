---
title: "Parameter recovery - PEDLR"
output:
  html_document:
    toc: yes
    self_contained: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 3
    number_sections: False
    highlight: pygments
    theme: cosmo
    code_folding: "hide"
    df_print: paged
    fig_caption: true
  pdf_document:
    toc: yes
    fig_caption: true
    latex_engine: xelatex
fig.align: "center"
header-includes:
  - \usepackage{fontspec}
  - \setmainfont{AgfaRotisSansSerif}
email: koch@mpib-berlin.mpg.de
---

# Pre set-up

- Import libraries

```{r message=FALSE}
library(reshape2)
library(ggplot2)
library(plotly)
library(plyr)
library(Rfast)
library(data.table)
library(knitr)
#library(rstudioapi)
#library(here)
library(viridis)
library(nloptr)
library(optimr)
```

- Set paths

```{r}
base_path = file.path('/Volumes', 'MPRG-Neurocode', 'Users', 'christoph', 'pedlr')
derivatives_path = file.path(base_path, 'derivatives', 'simulation')
source_path = file.path(base_path, 'code', 'simulation')
```


- Import own functions

```{r}
# Get path current script is in
#source_path = file.path(here(), 'simulation', 'final_sim', fsep=.Platform$file.sep)
#source_path = getSourceEditorContext()$path

# For knitting


# Source functions required for this script
source(file.path(source_path, 'Beta_pseudo_sim.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Gaussian_pseudo_sim.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Create_design.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Create_design_var_forced.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Create_miniblock.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Create_miniblock_var_forced.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'PE_dep_LR_choice_model.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'PE_dep_LR_choice_model_alt.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'PE_dep_LR_choice_model_interdep.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'Softmax_choice.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'PE_dep_LR_single_model.R', fsep = .Platform$file.sep))

```

- Set color scheme

```{r}
color = data.frame(matrix(NA, 1, 3))
colnames(color) = c('gaussian', 'loss', 'gain')
color[1,] = c('#ffed76', '#ff7698', '#76bfff')
```

# Softmax showcase

```{r}
# Prepare sampling
smax = c()
data_smax = data.frame(matrix(NA,0,3))
colnames(data_smax) = c('smax', 'diff', 'temp')
val = seq(0,100,by=0.1)

# Different functions for temperature
for(temp in c(1:30)){
  # Sample Softmax for each diff between values
  for(value_count in 1:length(val)){
    value = val[value_count]
    smax[value_count] = exp(value/temp) / (exp(value/temp) + exp(50/temp))
  }
  # Save results into data frame
  data = data.frame(smax)
  data$diff = val-50
  data$temp = temp
  # Append data for each temperature
  data_smax = rbind(data_smax, data)
}

# Turn temp into categorical variable
data_plot = data_smax
# Plot different softmax functions
data_plot$temp = as.factor(data_plot$temp)
p_softmax = ggplot(data=data_plot, aes(x=diff, y=smax, color=temp)) +
  geom_line() +
  scale_color_viridis(option='D', discrete = TRUE)
ggplotly(p_softmax)
```


# Parameter set-up

- Set up reward space
```{r}
# Reward lower and upper boundary
reward_space_lb = 1
reward_space_ub = 100

# Set up space for plotting
reward_space_length = 1000
reward_space = seq(reward_space_lb, 
                   reward_space_ub,
                   length=reward_space_length)
```

- Gaussian parameters and distribution
```{r}
# Parameters
gaussian_mean = (100 * 1/6) * 3
gaussian_sd = (100 * 1/6) / 3

# Distribution
gaussian_densities = dnorm(reward_space, gaussian_mean, gaussian_sd)
# Normalize density
gaussian_densities = scale(gaussian_densities) - min(scale(gaussian_densities))
```

- Beta parameters and distributions
```{r}
# Set up "skewdness" parameter for easier change of slope
beta_skewedness = 5
# Parameters for lower end beta and upper end beta
beta_a_le = beta_skewedness/3
beta_b_le = 2*beta_skewedness/3
beta_a_ue = 2*beta_skewedness/3
beta_b_ue = beta_skewedness/3
# Create distributions
beta_densities_le = dbeta(seq(0,1,length=reward_space_length), beta_a_le,beta_b_le)
beta_densities_ue = dbeta(seq(0,1,length=reward_space_length), beta_a_ue,beta_b_ue)
# Normalize densities
beta_densities_le = scale(beta_densities_le) - min(scale(beta_densities_le))
beta_densities_ue = scale(beta_densities_ue) - min(scale(beta_densities_le))
```

- Set rare event threshold
```{r}
# Set rare events to be 20% of the sampled data
rare_lim = 0.2
```

- Set parameters to recover

```{r}
alpha0 = 0.3
alpha1 = 0.6
interdep = 0.5
temperature = 2
```

---

# Set data to recover

- Create design

```{r}
# Set number of miniblocks (n*120)
n_miniblock = 6
# Set amount of forced choice trials (20 vs. 10 percent)
perc_forced = 20

dist1_val1 = 3/6*100
dist1_val2 = gaussian_sd
dist2_val1 = beta_a_ue
dist2_val2 = beta_b_ue
dist3_val1 = 5/6*100
dist3_val2 = gaussian_sd
two_betas = FALSE
reward_space_lb = reward_space_lb
reward_space_ub = reward_space_ub

# Create design based on function
design = Create_design_var_forced(n_miniblock,
                                  perc_forced,
                                  3/6*100, gaussian_sd,
                                  beta_a_ue, beta_b_ue,
                                  5/6*100, gaussian_sd,
                                  two_betas = FALSE,
                                  reward_space_lb, reward_space_ub)

```

- Create data for single participant

```{r}
# Set up matrix to store data in (to append subjects)
data_model = data.frame(matrix(0,0,18))

# Create matrix to store data for each subject
results = data.frame(matrix(0,nrow(design),ncol(data_model)))
results[,1] = 1
results[,2] = c(1:nrow(design))
results[,3] = design$option_left
results[,4] = design$option_right
results[,5] = design$reward_stim_1
results[,6] = design$reward_stim_2
results[,7] = design$comp_number

# Let model run over design matrix
sim = PE_dep_LR_choice_model_interdep(design,
                                      alpha0,
                                      alpha1,
                                      interdep,
                                      temperature,
                                      reward_space_ub,
                                      'softmax')

# Save model values, PE and fPE for ech trial and subject into matrix
results[,8] = sim$choices$choice
results[,9] = sim$choices$choice_prob
results[,10:12] = sim$values
results[,13:15] = sim$PE
results[,16:18] = sim$fPE

# Append all subjects
data_model = rbind(data_model, results)

# Convert to data frame (How our data will look like in the study)
data_model = data.frame(data_model)
colnames(data_model) = c('sub_id', 'trial', 'stim_1', 'stim_2',
                         'reward_stim_1', 'reward_stim_2', 'comp_number', 'choice', 'choice_prob',
                         'v_stim_1', 'v_stim_2', 'v_stim_3',
                         'pe_stim_1', 'pe_stim_2', 'pe_stim_3',
                         'fpe_stim_1', 'fpe_stim_2', 'fpe_stim_3')
# Sort after participants
data_model = data_model[order(data_model$sub_id),]
```

# Log-likelihod function

```{r}
Log_Likelihood = function(x, design, data){
  
  # Set vector entries to reflect parameters
  params.alpha0 = x[1]
  params.alpha1 = x[2]
  params.interdep = x[3]
  params.temperature = x[4]
  
  # Get choices of participant
  choices_participant = data$choice
  
  # Call model to obtain model values
  model = PE_dep_LR_choice_model_interdep(design,
                                          alpha0,
                                          alpha1,
                                          interdep,
                                          temperature,
                                          reward_space_ub,
                                          'softmax')
  
  # Get choices and probability of choices of model
  choices_model = model$choices$choice
  choices_prob_model = model$choices$choice_prob
  
  # Exclude forced choices (since here there is no choice probability and in turn no likelihood of choice)
  choices_participant = choices_participant[design$trial_type == 'choice']
  choices_model = choices_model[design$trial_type == 'choice']
  choices_prob_model = choices_prob_model[design$trial_type == 'choice']
  
  # Throw away NA of last entry
  choices_participant = na.omit(choices_participant)
  choices_model = na.omit(choices_model)
  choices_prob_model = na.omit(choices_prob_model)
  
  # Set up vector holding likelihood of given choice
  likelihood = vector(mode = 'numeric', length = length(choices_model))
  # Compare participants choice to models choice and see where they are the same
  choice_comp = (choices_participant == choices_model)
  # When choices are the same, take choice probability of trial as likelihood
  likelihood[choice_comp] = choices_prob_model[choice_comp]
  # When choices are different, take (1-choice probability) of trial as likelihood
  likelihood[!choice_comp] = 1-choices_prob_model[!choice_comp]
  
  # Log liklihood
  likelihood = log(likelihood)
  # Sum up log likelihood over all choices
  likelihood = sum(likelihood)
  # Negative log likelihood
  likelihood = -likelihood
  
  # Return negative log likelihood
  return(likelihood)
}
```

- Get log-likelihood distributions for different parameter combinations (on same design)

```{r}
# Define function to sample likelihood for specific parameter combination
sample_ll = function(alpha0, alpha1, intedep, temperature, n_iterations, data, design){
  x = c(alpha0, alpha1, interdep, temperature)
  
  data_ll_dist = data.frame(matrix(NA, n_iterations, 2))
  colnames(data_ll_dist) = c('iteration', 'll')
  
  data_ll_dist$iteration = c(1:n_iterations)
  
  for(i in c(1:n_iterations)){
    data_ll_dist$ll[i] = Log_Likelihood(x, data = data_model, design = design)
  }
  
  return(data_ll_dist)
}

# Prepare data to store sampled likelihood
data_ll_dist = data.frame(matrix(NA, 0, 3))
colnames(data_ll_dist) = c('iteration', 'params', 'll')

# Set number of samples
n_iterations = 500
# Parameters to recover
x = c(0.3,0.6,0.5,1)

# sample likelihood for correct parameters
data = sample_ll(x[1], x[2], x[3], x[4], n_iterations, data, design)
# store into data frame
data$params = 'correct'
data_ll_dist = rbind(data_ll_dist, data)

# sample likelihood for wrong parameters
# Different parameters
x = c(0,0,0,1)
data = sample_ll(x[1], x[2], x[3], x[4], n_iterations, data, design)
data$params = 'false'
data_ll_dist = rbind(data_ll_dist, data)

# Plot distribution for both recovery attempts
p_ll_sample = ggplot(data=data_ll_dist, aes(x=ll, fill=params, color=params)) +
  geom_density(color=NA, alpha=0.6) +
  geom_rug(alpha=0.6, sides = 't') +
  labs(x='Negative Log Likelihood')
  
p_ll_sample
```

---

# Optimization function

- Optimization function (nlopter)

```{r}
# Initial values for parameters
x = c(runif(1,0,1), runif(1,0,1), runif(1,0,1), runif(1,0.5,10))

# Define algorithm
opts = list('algorithm'='NLOPT_LN_COBYLA', 'xtol_rel'=1.0e-8)
# Solve function for minimum
opt = nloptr(x0=x,
             eval_f=Log_Likelihood,
             lb=c(0,0,0,0.5),
             ub=c(1,1,1,10),
             opts=opts,
             data=data_model,
             design=design)

# Print recovery results
cat('Real params:\t', c(0.3,0.6,0.5,7), '\n')
cat('Initial values:\t', x, '\n')
cat('Recovery:\t', opt$solution, '\n')
```

- Optimization using Optimr

```{r}
# List of control parameters
control = list('maximize'=FALSE)

# Randomly sampled initial values
x = c(runif(1,0,1), runif(1,0,1), runif(1,0,1), runif(1,0.5,10))

opt = optimr(par = x,
             fn = Log_Likelihood,
             method = list('L-BFGS-B'),
             lower = x,
             upper = c(1,1,1,10),
             #control = control,
             data=data_model,
             design=design)

# Print recovery results
cat('Real params:\t', c(0.3,0.6,0.5,2), '\n')
cat('Initial values:\t', x, '\n')
cat('Recovery:\t', opt$par, '\n')
```

---

# Parameter recovery check

- Function for parameter recovery taking parameters to recover, and trying to recover them

```{r}
Parameter_Recovery = function(attempts,
                              n_miniblocks,
                              perc_forced,
                              two_betas,
                              param1.le, param2.le,
                              param1.mid, param2.mid,
                              param1.ue, param2.ue,
                              reward_space_lb, reward_space_ub,
                              alpha0, alpha1, interdep, temperature, policy,
                              random_init=TRUE,
                              lower_bound,
                              upper_bound){
  
  # Initialize df to hold recovery data
  data_recovery = data.frame(matrix(NA,0,8))
  colnames(data_recovery) = c('attempts',
                              'true_alpha0',
                              'true_alpha1',
                              'true_interdep',
                              'parameter',
                              'true_value',
                              'init_value',
                              'recovery')
  
  # Loop over number of attempts
  for(attempt_count in c(1:attempts)){
    
    # Data frame to store result of attempt in
    result = data.frame(matrix(NA,4,8))
    colnames(result) = colnames(data_recovery)
    result$attempts = attempt_count
    result$true_alpha0 = alpha0
    result$true_alpha1 = alpha1
    result$true_interdep = interdep
    result$parameter = c('alpha0', 'alpha1', 'interdep', 'temperature')
    result$true_value = c(alpha0, alpha1, interdep, temperature)
    
    # Create design based on function
    design = Create_design_var_forced(n_miniblocks,
                                      perc_forced,
                                      param1.le, param2.le,
                                      param1.mid, param2.mid,
                                      param1.ue, param2.ue,
                                      two_betas = two_betas,
                                      reward_space_lb, reward_space_ub)
    
    # Set up matrix to store data in
    data_model = data.frame(matrix(0,0,18))
    # Create matrix to store data for each subject
    results = data.frame(matrix(0,nrow(design),ncol(data_model)))
    results[,1] = 1
    results[,2] = c(1:nrow(design))
    results[,3] = design$option_left
    results[,4] = design$option_right
    results[,5] = design$reward_stim_1
    results[,6] = design$reward_stim_2
    results[,7] = design$comp_number
    # Let model run over design matrix
    sim = PE_dep_LR_choice_model_interdep(design,
                                          alpha0,
                                          alpha1,
                                          interdep,
                                          temperature,
                                          reward_space_ub,
                                          'softmax')
    # Save model values, PE and fPE for ech trial and subject into matrix
    results[,8] = sim$choices$choice
    results[,9] = sim$choices$choice_prob
    results[,10:12] = sim$values
    results[,13:15] = sim$PE
    results[,16:18] = sim$fPE
    # Append all subjects
    data_model = rbind(data_model, results)
    # Convert to data frame (How our data will look like in the study)
    data_model = data.frame(data_model)
    colnames(data_model) = c('sub_id', 'trial', 'stim_1', 'stim_2',
                             'reward_stim_1', 'reward_stim_2', 'comp_number', 'choice', 'choice_prob',
                             'v_stim_1', 'v_stim_2', 'v_stim_3',
                             'pe_stim_1', 'pe_stim_2', 'pe_stim_3',
                             'fpe_stim_1', 'fpe_stim_2', 'fpe_stim_3')
    
    # Try to recover parameter by choices for specific design
    # Initial values for parameters (random or not based on function input)
    if(random_init){
      x = c(runif(1,0,1), runif(1,0,1), runif(1,0,1), runif(1,0.5,10))  
    }else if(!random_init){
      x = c(0,0,0,0.5)
    }
    
    # Enter initial values into results
    result$init_value = x
    
    # Define algorithm
    opts = list('algorithm'='NLOPT_LN_COBYLA', 'xtol_rel'=1.0e-8)
    # Solve function for minimum
    opt = nloptr(x0=x,
                 eval_f=Log_Likelihood,
                 lb=lower_bound,
                 ub=upper_bound,
                 opts=opts,
                 data=data_model,
                 design=design)
    
    # Save recovery to data frame
    result$recovery = opt$solution
    
    # Append different attempts
    data_recovery = rbind(data_recovery, result)
  }
  
  # Return data recovery
  return(data_recovery)
}
```

- Run parameter recovery in dependency of different parameters

```{r}
# Only run if there is no .tsv file with this data already
file = file.path(derivatives_path, 'param_recovery_loop.tsv')
if(file.exists(file)){
  data_recovery = read.table(file, sep='\t', header = TRUE)
}else if(!file.exists(file)){
  
  # Define non-looping parameters
  attempts = 5
  n_miniblocks = 6
  perc_forced = 20
  two_betas = TRUE
  param1.le=beta_a_le
  param2.le=beta_b_le
  param1.mid=gaussian_mean
  param2.mid=gaussian_sd
  param1.ue=beta_a_ue
  param2.ue=beta_b_ue
  reward_space_lb=1
  reward_space_ub=100
  temperature=1
  policy='softmax'
  
  # Initialize df to hold recovery data
  data_recovery = data.frame(matrix(NA,0,8))
  colnames(data_recovery) = c('attempts',
                              'true_alpha0',
                              'true_alpha1',
                              'true_interdep',
                              'parameter',
                              'true_value',
                              'init_value',
                              'recovery')
  
  # Loop over free parameters
  for(alpha0 in seq(0.2, 1, by=0.4)){
    for(alpha1 in seq(0.2, 1, by=0.4)){
      for(interdep in seq(0.2, 0.2)){
        
        # Run Recovery
        data_recovery = rbind(data_recovery,
                              Parameter_Recovery(attempts,
                                                 n_miniblocks,
                                                 perc_forced,
                                                 two_betas,
                                                 param1.le, param2.le,
                                                 param1.mid, param2.mid,
                                                 param1.ue, param2.ue,
                                                 reward_space_lb, reward_space_ub,
                                                 alpha0, alpha1, interdep, temperature, policy,
                                                 random_init=TRUE,
                                                 lower_bound=c(0,0,0,0.5),
                                                 upper_bound=c(1,1,1,10)))
      }
    }
  }
  
  # Write results to .tsv file
  write.table(data_recovery, file, sep='\t', row.names = FALSE)
  
}
```

- Plot recovery

```{r}
# Fix Interdependence parameter
data_plot = subset(data_recovery, true_interdep == 0.2)
# Eliminate temperature recovery
data_plot = data_plot[!data_plot$parameter == 'temperature',]

# Change from init values
p_recovery = ggplot(data=data_plot, aes(x=parameter, y=recovery, color=parameter)) +
  theme_bw() +
  geom_point(position = position_nudge(x=-0.2)) +
  geom_point(aes(y=init_value), shape=5) +
  geom_point(aes(y=true_value), shape=4, size=2, position = position_nudge(x=0.2)) +
  facet_grid(rows = vars(true_alpha0), cols = vars(true_alpha1), labeller = 'label_both') +
  labs(title='Recovered values (full), initial values (empty) and true value (cross)')

p_recovery
```

