---
title: "PEDLR - Simulation"
output:
  html_document:
    toc: yes
    self_contained: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 3
    number_sections: False
    highlight: pygments
    theme: cosmo
    code_folding: "hide"
    df_print: paged
    fig_caption: true
  pdf_document:
    toc: yes
    fig_caption: true
    latex_engine: xelatex
fig.align: "center"
header-includes:
  - \usepackage{fontspec}
  - \setmainfont{AgfaRotisSansSerif}
email: koch@mpib-berlin.mpg.de
---

# Paths and libraries

- Install packages if necessary

```{r}
# install.packages(c('reshape2',
#                    'ggplot2',
#                    'plotly',
#                    'plyr',
#                    'Rfast',
#                    'data.table',
#                    'knitr',
#                    'viridis',
#                    'cowplot',
#                    'here',
#                    'optparse'),
#                  repos='http://ftp5.gwdg.de/pub/misc/cran/')
```


- Import libraries

```{r message=FALSE}
library(reshape2)
library(ggplot2)
library(plotly)
library(plyr)
library(Rfast)
library(data.table)
library(knitr)
#library(rstudioapi)
#library(here)
library(viridis)
library(cowplot)
library(here)
library(optparse)
```


- Set paths

```{r}
base_path = file.path(here::here(), fsep = .Platform$file.sep)
derivatives_path = file.path(base_path, 'derivatives', 'simulation',
                             fsep = .Platform$file.sep)
source_path = file.path(base_path, 'code', fsep = .Platform$file.sep)
```

- Import own functions

```{r}
# Source functions required for this script
source(file.path(source_path, 'design', 'Beta_pseudo_sim.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'design', 'Gaussian_pseudo_sim.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'design', 'Uniform_pseudo_sim.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'design', 'Bimodal_pseudo_sim.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'design', 'Create_design_complete.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Sample_subjects.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'models', 'Pedlr.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'models', 'Pedlr_interdep.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'models', 'Softmax_choice.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Apply_model.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Model_results.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Model_bias_value.R', fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Model_perc_correct.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Model_bias_correct.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Free_bimodal_modes.R',
                 fsep = .Platform$file.sep))
source(file.path(source_path, 'simulation', 'Free_bimodal_means.R',
                 fsep = .Platform$file.sep))
```

---

# Parameter set-up

## Model

- Model parameters

```{r}
alpha0 = 0.3
alpha1 = 0.7
temperature = 7
```

- Set up reward space

```{r}
# Reward lower and upper boundary
reward_space_lb = 1
reward_space_ub = 100

# Set up space for plotting
reward_space_length = 1000
reward_space = seq(reward_space_lb, 
                   reward_space_ub,
                   length=reward_space_length)
```

- Set rare event threshold

```{r}
# Set rare events to be 20% of the sampled data
rare_lim = 0.2
```


## Distributions

### Gaussian

```{r}
# Parameters
gaussian_mean = (100 * 1/6) * 3
gaussian_sd = (100 * 1/6) / 3

# Distribution
gaussian_densities = dnorm(reward_space, gaussian_mean, gaussian_sd)
# Normalize densities
gaussian_densities = scale(gaussian_densities) - min(scale(gaussian_densities))
```

### Beta

```{r}
# Set up "skewdness" parameter for easier change of slope
beta_skewedness = 5
# Parameters for lower end beta and upper end beta
beta_a_le = beta_skewedness/3
beta_b_le = 2*beta_skewedness/3
beta_a_ue = 2*beta_skewedness/3
beta_b_ue = beta_skewedness/3
# Create distributions
beta_densities_le = dbeta(seq(0,1,length=reward_space_length),
                          beta_a_le,beta_b_le)
beta_densities_ue = dbeta(seq(0,1,length=reward_space_length),
                          beta_a_ue,beta_b_ue)
# Normalize densities
beta_densities_le = scale(beta_densities_le) - min(scale(beta_densities_le))
beta_densities_ue = scale(beta_densities_ue) - min(scale(beta_densities_le))
```

### Uniform

```{r}
# Parameters
uniform_min = reward_space_lb
uniform_max = reward_space_ub

# Distribution (cannot be normalized because of sd = 0)
uniform_densities = dunif(reward_space, uniform_min, uniform_max)
# Make distirbution visible in plot
uniform_densities = uniform_densities + 0.3
```

### Bimodal

```{r}
# Parameters
# Mean of whole distribution
bimodal_mean = (100 * 1/6) * 2
# Distance between mounts
bimodal_distance = 40
# Relative proportion of sampling different modes
bimodal_rel_proportion = 0.2
# Mean of both modes depending on mean of whole distribution
bimodal_main_mean = (bimodal_mean - 
                       ((bimodal_rel_proportion * bimodal_distance) / 
                          (bimodal_rel_proportion + 1)))
bimodal_second_mean = bimodal_main_mean + bimodal_distance
# Sd of main and second mode
bimodal_main_sd = gaussian_sd
bimodal_second_sd = gaussian_sd

# Distribution
# Get probability to sample each value over reward space given main distribution
bimodal_main_densities = dnorm(reward_space,
                               mean = bimodal_main_mean,
                               sd = bimodal_main_sd)
# Get probability to sample each value over reward space given second 
# distribution
bimodal_second_densities = dnorm(reward_space,
                                 mean = bimodal_second_mean,
                                 sd = bimodal_second_sd)
# Fuse sample probabilities given relative ratio of second distribution
bimodal_densities = (bimodal_main_densities + 
                       bimodal_rel_proportion * bimodal_second_densities)
# Normalize densities
bimodal_densities = scale(bimodal_densities) - min(scale(bimodal_densities))
```

---

# Control plots

## Density functions of used distributions

- Plot distributions

```{r out.width='100%', warning=FALSE}
# Form data frame from density values
data_densities = data.frame(reward_space, 
                            gaussian_densities,
                            beta_densities_le,
                            beta_densities_ue,
                            uniform_densities,
                            bimodal_densities)
colnames(data_densities) = c('reward_space',
                             'Gaussian',
                             'Beta (gain)',
                             'Beta (loss)',
                             'Uniform',
                             'Bimodal')

# Bring data frame into long format
data_densities = melt(data_densities, id.vars='reward_space')

# Disribution plot
p_dist = ggplot(data=data_densities, aes(x=reward_space,
                                         y=value,
                                         group=as.factor(variable),
                                         color=as.factor(variable))) +
  geom_line(size=1) +
  #scale_color_manual(values = c(color$gaussian, color$gain, color$loss)) +
  scale_x_continuous(limits = c(1,100)) +
  #stat_summary(fun.data = 'mean', geom = 'vline') +
  geom_vline(xintercept=c(1/3, 1/2, 2/3)*100,
             linetype='dashed',
             alpha=0.5,
             size=0.1) +
  labs(title='Density functions of used distributions',
       x='Outcome',
       y='Normalized density',
       color='Distributions') +
  scale_y_continuous(limits=c(0,4.5)) +
  theme(plot.title=element_text(size=15, face='bold', hjust=0.5),
        axis.title=element_text(size=12))

p_dist
```

**Annotation:** This plot does not correctly reflect the normalized density of 
the **uniform distribution**. 
Because it's standard deviation is 0 it cannot be normalized. The uniform 
density was **artificially raised** to be visible in comparison to the other 
density functions.

## Sampling functions

- Sample rewards from distributions (depending on how many blocks use the same 
distributions)

```{r out.width='100%', warning=FALSE}

# Create template of plotting data frame
data_sampling = data.frame(matrix(NA, 0, 4))
colnames(data_sampling) = c('Samples', 'n_blocks', 'variable', 'value')

# Loop over different amount of blocks for a task (depending on design)
for(block_count in seq(3)){
  
  # Define parameters
  # (each block has 80 samples for each of the three distributions used)
  n_samples = block_count * 80
  data = data.frame(c(1:n_samples))
  colnames(data) = 'Sample'
  data$n_blocks = block_count
  
  # Fill data frame with samples
  data$beta_le = Beta_pseudo_sim(n_samples,
                                 beta_a_le,
                                 beta_b_le,
                                 'b_le',
                                 reward_space_lb,
                                 reward_space_ub)$outcome
  data$gaussian = Gaussian_pseudo_sim(n_samples,
                                      gaussian_mean,
                                      gaussian_sd,
                                      'g_an',
                                      reward_space_lb,
                                      reward_space_ub)$outcome
  data$beta_ue = Beta_pseudo_sim(n_samples,
                                 beta_a_ue,
                                 beta_b_ue,
                                 'b_ue',
                                 reward_space_lb,
                                 reward_space_ub)$outcome
  data$uniform = Uniform_pseudo_sim(n_samples,
                                    uniform_min,
                                    uniform_max,
                                    'uniform',
                                    reward_space_lb,
                                    reward_space_ub)$outcome
  data$bimodal = Bimodal_pseudo_sim(n_samples,
                                    mean = bimodal_mean,
                                    rel_proportion = bimodal_rel_proportion,
                                    distance = bimodal_distance,
                                    main.sd = bimodal_main_sd,
                                    second.sd = bimodal_second_sd,
                                    dist_name = 'bimodal',
                                    reward_space_lb,
                                    reward_space_ub)$outcome
  data = melt(data, id.vars=c('Sample', 'n_blocks'))
  
  data_sampling = rbind(data_sampling, data)
}
```

- Plot samples for each distribution and number of blocks

```{r, out.width="100%"}
# Plot histograms
p_sampling = ggplot(data=data_sampling, aes(x=value, fill=variable)) +
  #scale_fill_manual(values=c(color$gain, color$gaussian, color$loss)) +
  geom_histogram(binwidth = 1) +
  facet_grid(rows = vars(n_blocks), cols = vars(variable))

p_sampling
```

**Annotation:** This plot illustates that **equal sampling of the whole space** 
is only possible if there are **enough events** for each distribution. Two 
blocks per task should be recommended so the sampled values are appropriately 
reflecting the distribution they come from. 

---

# Model simulations

- Set number of subjects

```{r}
n_subjects = 40
```

- Set distributions for task design

```{r}
# Gaussian
# SD similar for all Gaussians
gaussian_sd = (100 * 1/6) / 3
# Mean of different Gaussians
# Lower end
gaussian_le_mean = (100 * 1/6) * 1
# Mid
gaussian_mid_mean = (100 * 1/6) * 3
# Upper end
gaussian_ue_mean = (100 * 1/6) * 5

# Betas
# Set up "skewdness" parameter for easier change of slope
beta_skewedness = 5
# Gain Beta
beta_a_gain = beta_skewedness/3
beta_b_gain = 2*beta_skewedness/3
# Loss Beta
beta_a_loss = 2*beta_skewedness/3
beta_b_loss = beta_skewedness/3

# Uniform
uniform_min = reward_space_lb
uniform_max = reward_space_ub

# Bimodal
# Same sd for each mode
bimodal_sd = gaussian_sd
# Same relative proportion (between modes) for both bimodals
bimodal_rel_proportion = 0.2
## Overall mean bimodal distributions
bimodal_mean_gain = (100 * 1/6) * 2
bimodal_mean_loss = (100 * 1/6) * 4
# Distance between modes in gain and loss bimodal
bimodal_distance_gain = 40
bimodal_distance_loss = -40

```

- Set parameters for task design

```{r}
# Number of overall blocks
n_blocks = 6
# Number of blocks dedicated to each task version
blocks_per_task = 3
# Percentage of forced choice trials
perc_forced = 20
# List of different distributions with parameters (three distributions for each 
# task version)
dist_list = list(c('gaussian', gaussian_le_mean, gaussian_sd),
                 c('bimodal',
                   bimodal_mean_gain,
                   bimodal_rel_proportion,
                   bimodal_distance_gain,
                   bimodal_sd,
                   bimodal_sd),
                 c('gaussian', gaussian_mid_mean, gaussian_sd),
                 c('gaussian', gaussian_mid_mean, gaussian_sd),
                 c('bimodal',
                   bimodal_mean_loss,
                   bimodal_rel_proportion,
                   bimodal_distance_loss,
                   bimodal_sd,
                   bimodal_sd),
                 c('gaussian', gaussian_ue_mean, gaussian_sd))
```

- Plot samples for each task version

```{r}
# Create design to get sampling for each distribution in each task version
design = Create_design(n_blocks = n_blocks,
                       perc_forced = perc_forced,
                       blocks_per_task = blocks_per_task,
                       dist_list = dist_list)

# Create template to check sampling of each distribution
data_plot = data.frame(matrix(NA, 0, 3))
colnames(data_plot) = c('task_version', 'stimulus', 'samples')

# For each task version
for(version_count in unique(design$task_version)){
  data = subset(design, task_version == version_count)
  # For each of the three distributions per task version
  for(stim_count in sort(unique(data$option_left))){
    # Get data frame of rewards sampled for each stimulus (regardless if 
    # presented left or right) and task version
    samples = data.frame(c(data$reward_stim_1[data$option_left == stim_count],
                data$reward_stim_2[data$option_right == stim_count]))
    samples$task_version = version_count
    samples$stimulus = stim_count
    colnames(samples) = c('samples', 'task_version', 'stimulus')
    # Add samples to plotting data
    data_plot = rbind(data_plot, samples)
  }
}

# Prepare for plotting
data_plot$stimulus = as.factor(data_plot$stimulus)
# Plot sampling for each task version and stimulus
p_sampling = ggplot(data = data_plot,
                    aes(x = samples,
                        fill = stimulus,
                        group = stimulus)) +
  geom_histogram(binwidth = 1,
                 position = 'identity',
                 alpha = 0.7) +
  # facet_grid(rows = vars(task_version),
  #            cols = vars(stimulus))
  facet_wrap(~ task_version)

# Display plot
p_sampling
```

- Simulate data for number of subjects

```{r}
data_sim = Sample_subjects(n_subjects = n_subjects,
                           set_seed = TRUE,
                           n_blocks = n_blocks,
                           perc_forced = perc_forced,
                           blocks_per_task = blocks_per_task,
                           dist_list = dist_list)
```

## Apply models

### Pedlr

- Set model parameters

```{r}
alpha0 = 0.3
alpha1 = 0.7
temperature = 7
choice_policy = 'softmax'
init_values = list(c(50,50,50),
                   c(50,50,50))

# Convert to data frame to pass to function
parameters = data.frame(matrix(NA, 1, 5))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'reward_space_ub',
                         'choice_policy')
parameters$alpha0 = alpha0
parameters$alpha1 = alpha1
parameters$temperature = temperature
parameters$reward_space_ub = reward_space_ub
parameters$choice_policy = choice_policy
```

- Apply model to each simulated subject

```{r}
data_model = ddply(data_sim,
                   "sub_id",
                   Apply_model,
                   model = 'Pedlr',
                   parameters = parameters,
                   init_values = init_values)
```

#### Results

```{r, out.width="100%"}
results = Model_results(results = data_model,
                     last_perc_of_trials = 25,
                     average_subjects = TRUE,
                     mean_value_calculation = 'chosen_trials')
data_bias = results$bias
plot = results$plot
plot
```

### Pedlr_interdep

- Set model parameters

```{r}
alpha0 = 0.3
alpha1 = 0.7
temperature = 7
choice_policy = 'softmax'
interdep = 0.5
init_values = list(c(50,50,50),
                   c(50,50,50))

# Convert to data frame to pass to function
parameters = data.frame(matrix(NA, 1, 6))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'reward_space_ub',
                         'choice_policy',
                         'interdep')
parameters$alpha0 = alpha0
parameters$alpha1 = alpha1
parameters$temperature = temperature
parameters$reward_space_ub = reward_space_ub
parameters$choice_policy = choice_policy
parameters$interdep = interdep
```

- Apply model to each simulated subject

```{r}
data_model = ddply(data_sim,
                   "sub_id",
                   Apply_model,
                   model = 'Pedlr_interdep',
                   parameters = parameters,
                   init_values = init_values)
```

#### Results

```{r, out.width="100%"}
results = Model_results(results = data_model,
                        last_perc_of_trials = 25,
                        average_subjects = TRUE,
                        mean_value_calculation = 'chosen_trials')
data_bias = results$bias
plot = results$plot
plot
```

---

# Bias analysis

See how the bias between real (sampling) mean and estimated mean develops 
depending on model parameters.


- Set shared variables for different models

```{r}
# Number of subjects to simulate
n_subjects = 40
# Parameters for design creation
set_seed = TRUE
n_blocks = n_blocks
perc_forced = perc_forced
blocks_per_task = blocks_per_task
dist_list = dist_list
# Parameters for model running on designs (other model specific parameters vary 
# for bias assessment)
init_values = init_values
# Parameters for bias assessment
last_perc_of_trials = 35
average_subjects = TRUE
mean_value_calculation = 'chosen_trials'
```

- Create list of parameters to test

```{r}
# Steps in which to loop over each parameter
steps_alpha0 = seq(from = 0, to = 1, length.out = 6)
steps_alpha1 = seq(from = 0, to = 1, length.out = 6)
steps_temperature = seq(from = 1, to = 30, length.out = 6)
steps_policy = c('softmax')
steps_interdep = seq(from = 0.1, to = 0.9, length.out = 5)

# Get all combinations of parameters
parameters = data.table(expand.grid(steps_alpha0,
                                    steps_alpha1,
                                    steps_temperature,
                                    steps_policy,
                                    steps_interdep))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'choice_policy',
                         'interdep')

# Add constant parameters
parameters$reward_space_ub = reward_space_ub
```

### Pedlr

- Assess bias for different parameters

```{r}
# Set model for simulation
model = 'Pedlr'

# Parameters to save and loas data output
file = file.path(derivatives_path, 'bias_simulation_pedlr.tsv')
save_data = FALSE
save_file = file
load_data = TRUE
load_file = file

# Assess bias (if load data is true it will load .tsv of data_bias)
bias = Model_bias_value(n_subjects = n_subjects,
                        set_seed = set_seed,
                        n_blocks = n_blocks,
                        perc_forced = perc_forced,
                        blocks_per_task = blocks_per_task,
                        dist_list = dist_list,
                        model = model,
                        parameters = parameters,
                        init_values = init_values,
                        last_perc_of_trials = last_perc_of_trials,
                        average_subjects = average_subjects,
                        mean_value_calculation = mean_value_calculation,
                        save_data = save_data,
                        save_file = save_file,
                        load_data = load_data,
                        load_file = load_file)

data_bias = bias$bias
bias$plot_softmax
```


### Pedlr_interdep

```{r}
# Set model for simulation
model = 'Pedlr_interdep'

# Parameters to save and load data output
file = file.path(derivatives_path, 'bias_simulation_pedlr_interdep.tsv')
save_data = FALSE
save_file = file
load_data = TRUE
load_file = file

# Assess bias (if load data is true it will load .tsv of data_bias)
bias = Model_bias_value(n_subjects = n_subjects,
                        set_seed = set_seed,
                        n_blocks = n_blocks,
                        perc_forced = perc_forced,
                        blocks_per_task = blocks_per_task,
                        dist_list = dist_list,
                        model = model,
                        parameters = parameters,
                        init_values = init_values,
                        last_perc_of_trials = last_perc_of_trials,
                        average_subjects = average_subjects,
                        mean_value_calculation = mean_value_calculation,
                        save_data = save_data,
                        save_file = save_file,
                        load_data = load_data,
                        load_file = load_file)

data_bias = bias$bias
```


---

# False choices

**Annotation:** This only holds in case the sampling means are hierarchical 
(reward_stim_1 < reward_stim_2 < reward_stim_3).

- Set shared variables for different models

```{r}
# Number of subjects to simulate
n_subjects = 10
# Parameters for design creation
set_seed = TRUE
n_blocks = 6
perc_forced = 30
blocks_per_task = 3
dist_list = dist_list
# Parameters for model running on designs (other model specific parameters vary 
# for bias assessment)
init_values = list(c(50,50,50),
                   c(50,50,50))
# Parameters for bias assessment
shrink_distance_vec = seq(0,3)
```

- Create list of parameters to test

```{r}
# Steps in which to loop over each parameter
steps_alpha0 = seq(from = 0.2, to = 1, length.out = 5)
steps_alpha1 = seq(from = 0.2, to = 1, length.out = 5)
steps_temperature = seq(from = 1, to = 30, length.out = 5)
steps_policy = 'softmax'
steps_interdep = seq(from = 0.1, to = 0.9, length.out = 5)

# Get all combinations of parameters
parameters = data.table(expand.grid(steps_alpha0,
                                    steps_alpha1,
                                    steps_temperature,
                                    steps_policy,
                                    steps_interdep))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'choice_policy',
                         'interdep')

# Add constant parameters
parameters$reward_space_ub = reward_space_ub
```

## Influence of distribution distance on correct choices

### Pedlr

#### All parameters

```{r, fig.width=6, fig.height=6}
# Set model for simulation
model = 'Pedlr'

# Parameters to save and load data output
file = file.path(derivatives_path, 'bias_correct_simulation_pedlr_fc30.tsv')
save_data = FALSE
save_file = file
load_data = TRUE
load_file = file

# Assess bias (if load data is true it will load .tsv of data_bias)
bias_correct = Model_bias_correct(n_subjects = n_subjects,
                                  set_seed = set_seed,
                                  n_blocks = n_blocks,
                                  perc_forced = perc_forced,
                                  blocks_per_task = blocks_per_task,
                                  dist_list = dist_list,
                                  model = model,
                                  parameters = parameters,
                                  init_values = init_values,
                                  shrink_distance_vec = shrink_distance_vec,
                                  save_data = save_data,
                                  save_file = save_file,
                                  load_data = load_data,
                                  load_file = load_file)
data_choice = bias_correct$data_bias_correct
bias_correct$plot
```

#### Fixed parameters

```{r}
# Steps in which to loop over each parameter
steps_alpha0 = 0.3
steps_alpha1 = 0.7
steps_temperature = 7
steps_policy = 'softmax'
steps_interdep = 0.5

# Get all combinations of parameters
parameters = data.table(expand.grid(steps_alpha0,
                                    steps_alpha1,
                                    steps_temperature,
                                    steps_policy,
                                    steps_interdep))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'choice_policy',
                         'interdep')

# Add constant parameters
parameters$reward_space_ub = reward_space_ub

# Parameters for bias assessment
shrink_distance_vec = round(seq(0,100/6, length.out = 50), 2)
```

```{r}
# Set model for simulation
model = 'Pedlr'

# Parameters to save and load data output
file = file.path(derivatives_path, 'shrinkage_simulation_pedlr_fc30.tsv')
save_data = FALSE
save_file = file
load_data = TRUE
load_file = file

# Assess bias (if load data is true it will load .tsv of data_bias)
bias_correct = Model_bias_correct(n_subjects = 100,
                                  set_seed = set_seed,
                                  n_blocks = n_blocks,
                                  perc_forced = perc_forced,
                                  blocks_per_task = blocks_per_task,
                                  dist_list = dist_list,
                                  model = model,
                                  parameters = parameters,
                                  init_values = init_values,
                                  shrink_distance_vec = shrink_distance_vec,
                                  save_data = save_data,
                                  save_file = save_file,
                                  load_data = load_data,
                                  load_file = load_file)
data_choice = bias_correct$data_bias_correct
bias_correct$plot
```

#### Prepare data for plotting

```{r}
data_balance = subset(data_choice, comp == '1v2')
data_balance = select(data_balance, -c(comp, perc_correct))
data_balance$corr_1v2 = subset(data_choice, comp == '1v2')$perc_correct
data_balance$corr_2v3 = subset(data_choice, comp == '2v3')$perc_correct
data_balance$corr_1v3 = subset(data_choice, comp == '1v3')$perc_correct
data_balance$balance = data_balance$corr_2v3 - data_balance$corr_1v2
# Balanced normalized with average correctness
data_balance$rel_balance = data_balance$balance / (data_balance$corr_1v3 - 0.5)

data_plot = data_balance
data_plot = ddply(data_plot, 
                   .(task_version, distance_shrinkage),
                   summarize,
                   mean_corr_1v2 = mean(corr_1v2),
                   mean_corr_2v3 = mean(corr_2v3),
                   mean_corr_1v3 = mean(corr_1v3),
                   mean_balance = mean(balance),
                   mean_rel_balance = mean(rel_balance))
data_plot$distance_shrinkage = as.factor(data_plot$distance_shrinkage)
data_plot$task_version = as.factor(data_plot$task_version)
```


##### Look at gradient of 1v2/2v3 correctness in dependence of shrinkage

Balance > 0: Higher dist higher correctness
Balance < 0: Lower dist higher correctness

```{r}
p = ggplot(data_plot, aes(x = distance_shrinkage, y = mean_balance)) +
  geom_point(size=0.5) +
  #stat_summary(fun = 'mean', geom = 'point', size = 1, color = 'red') +
  geom_vline(xintercept = as.factor(100/6), linetype='dashed', color='red') +
  facet_wrap(~task_version)

p
```

##### Look at gradient of 1v2/2v3 correctness in dependence of shrinkage with penalty

Value escalates the closer 1v3 gets to chance level (0.5)

```{r}
p = ggplot(data_plot, aes(x = distance_shrinkage, y = mean_rel_balance)) +
  geom_point(size=0.5) +
  #stat_summary(fun = 'mean', geom = 'point', size = 1, color = 'red') +
  scale_x_discrete(breaks=shrink_distance_vec[seq(1, length(seq(0,100/6, length.out=50)), by=5)]) +
  geom_vline(xintercept = as.factor(100/6), linetype='dashed', color='red') +
  facet_wrap(~task_version)

p
```

#### Adjust mode distance in bimodal distribution to counter sampling bias

```{r}
# Steps in which to loop over each parameter
steps_alpha0 = 0.3
steps_alpha1 = 0.7
steps_temperature = 7
steps_policy = 'softmax'
steps_interdep = 0.5

# Get all combinations of parameters
parameters = data.table(expand.grid(steps_alpha0,
                                    steps_alpha1,
                                    steps_temperature,
                                    steps_policy,
                                    steps_interdep))
colnames(parameters) = c('alpha0',
                         'alpha1',
                         'temperature',
                         'choice_policy',
                         'interdep')

# Add constant parameters
parameters$reward_space_ub = reward_space_ub

# Parameters for bias assessment
shrink_distance_vec = round(seq(0,100/6, length.out = 11), 2)
mode_distance_change_vec = seq(from = 0, to = 30, length.out = 11)
```

```{r}
# Set model for simulation
model = 'Pedlr'

# Parameters to save and load data output
file = file.path(derivatives_path, 'free_modes_pedlr_fc30.tsv')
save_data = FALSE
save_file = file
load_data = TRUE
load_file = file

outcome = Free_bimodal_modes(n_subjects = 100,
                             set_seed = set_seed,
                             n_blocks = n_blocks,
                             perc_forced = perc_forced,
                             blocks_per_task = blocks_per_task,
                             dist_list = dist_list,
                             model = model,
                             parameters = parameters,
                             init_values = init_values,
                             shrink_distance_vec = shrink_distance_vec,
                             save_data = save_data,
                             save_file = save_file,
                             load_data = load_data,
                             load_file = load_file,
                             mode_distance_change_vec = mode_distance_change_vec)
```

```{r}
data_plot = outcome
data_plot = ddply(data_plot,
                  .(task_version,
                    comp,
                    alpha0,
                    alpha1,
                    temperature,
                    choice_policy,
                    reward_space_ub,
                    distance_shrinkage,
                    bimodal_distance_change),
                  summarize,
                  mean_perc_correct = mean(perc_correct))

data_balance = subset(data_plot, comp == '1v2')
data_balance = select(data_balance, -c(comp, mean_perc_correct))
data_balance$corr_1v2 = subset(data_plot, comp == '1v2')$mean_perc_correct
data_balance$corr_2v3 = subset(data_plot, comp == '2v3')$mean_perc_correct
data_balance$corr_1v3 = subset(data_plot, comp == '1v3')$mean_perc_correct
data_balance$balance = data_balance$corr_2v3 - data_balance$corr_1v2
data_balance$distance_shrinkage = as.factor(data_balance$distance_shrinkage)


ggplot(data = data_balance, aes(x = bimodal_distance_change,
                             y = balance,
                             color = distance_shrinkage)) +
  geom_line() +
  scale_color_viridis(option='D', discrete = TRUE) +
  facet_wrap(~task_version)
```


<!-- --- -->

<!-- #### Free bimodal means -->

<!-- ```{r} -->
<!-- # Steps in which to loop over each parameter -->
<!-- steps_alpha0 = 0.3 -->
<!-- steps_alpha1 = 0.7 -->
<!-- steps_temperature = 7 -->
<!-- steps_policy = 'softmax' -->
<!-- steps_interdep = 0.5 -->

<!-- # Get all combinations of parameters -->
<!-- parameters = data.table(expand.grid(steps_alpha0, -->
<!--                                     steps_alpha1, -->
<!--                                     steps_temperature, -->
<!--                                     steps_policy, -->
<!--                                     steps_interdep)) -->
<!-- colnames(parameters) = c('alpha0', -->
<!--                          'alpha1', -->
<!--                          'temperature', -->
<!--                          'choice_policy', -->
<!--                          'interdep') -->

<!-- # Add constant parameters -->
<!-- parameters$reward_space_ub = reward_space_ub -->

<!-- # Parameters for bias assessment -->
<!-- shrink_distance_vec = round(seq(0,100/6, length.out = 11), 2) -->
<!-- bimodal_mean_vec = round(seq(0,100/6, length.out = 11), 2) -->

<!-- # Set model for simulation -->
<!-- model = 'Pedlr' -->

<!-- # Parameters to save and load data output -->
<!-- file = file.path(derivatives_path, 'free_means_pedlr_fc30.tsv') -->
<!-- save_data = FALSE -->
<!-- save_file = file -->
<!-- load_data = TRUE -->
<!-- load_file = file -->

<!-- outcome = Free_bimodal_modes(n_subjects = 100, -->
<!--                              set_seed = set_seed, -->
<!--                              n_blocks = n_blocks, -->
<!--                              perc_forced = perc_forced, -->
<!--                              blocks_per_task = blocks_per_task, -->
<!--                              dist_list = dist_list, -->
<!--                              model = model, -->
<!--                              parameters = parameters, -->
<!--                              init_values = init_values, -->
<!--                              shrink_distance_vec = shrink_distance_vec, -->
<!--                              save_data = save_data, -->
<!--                              save_file = save_file, -->
<!--                              load_data = load_data, -->
<!--                              load_file = load_file, -->
<!--                              mean_change_vec = bimodal_mean_vec) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- data_plot = outcome -->
<!-- data_plot = ddply(data_plot, -->
<!--                   .(task_version, -->
<!--                     comp, -->
<!--                     alpha0, -->
<!--                     alpha1, -->
<!--                     temperature, -->
<!--                     choice_policy, -->
<!--                     reward_space_ub, -->
<!--                     distance_shrinkage, -->
<!--                     bimodal_mean_change), -->
<!--                   summarize, -->
<!--                   mean_perc_correct = mean(perc_correct)) -->

<!-- data_balance = subset(data_plot, comp == '1v2') -->
<!-- data_balance = select(data_balance, -c(comp, mean_perc_correct)) -->
<!-- data_balance$corr_1v2 = subset(data_plot, comp == '1v2')$mean_perc_correct -->
<!-- data_balance$corr_2v3 = subset(data_plot, comp == '2v3')$mean_perc_correct -->
<!-- data_balance$corr_1v3 = subset(data_plot, comp == '1v3')$mean_perc_correct -->
<!-- data_balance$balance = data_balance$corr_2v3 - data_balance$corr_1v2 -->


<!-- ggplot(data = data_balance, aes(x = bimodal_mean_change, -->
<!--                              y = balance, -->
<!--                              color = distance_shrinkage)) + -->
<!--   geom_line() + -->
<!--   scale_color_viridis(option='D') + -->
<!--   facet_wrap(~task_version) -->
<!-- ``` -->


<!-- --- -->

<!-- ### Pedlr_interdep -->

<!-- #### All parameters -->

<!-- - Create list of parameters to test -->

<!-- ```{r} -->
<!-- # Steps in which to loop over each parameter -->
<!-- steps_alpha0 = seq(from = 0.2, to = 1, length.out = 5) -->
<!-- steps_alpha1 = seq(from = 0.2, to = 1, length.out = 5) -->
<!-- steps_temperature = seq(from = 1, to = 30, length.out = 5) -->
<!-- steps_policy = 'softmax' -->
<!-- steps_interdep = 0.5 -->

<!-- # Get all combinations of parameters -->
<!-- parameters = data.table(expand.grid(steps_alpha0, -->
<!--                                     steps_alpha1, -->
<!--                                     steps_temperature, -->
<!--                                     steps_policy, -->
<!--                                     steps_interdep)) -->
<!-- colnames(parameters) = c('alpha0', -->
<!--                          'alpha1', -->
<!--                          'temperature', -->
<!--                          'choice_policy', -->
<!--                          'interdep') -->

<!-- # Add constant parameters -->
<!-- parameters$reward_space_ub = reward_space_ub -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Set model for simulation -->
<!-- model = 'Pedlr_interdep' -->

<!-- # Parameters to save and load data output -->
<!-- file = file.path(derivatives_path, 'bias_correct_simulation_pedlr_interdep_fc30.tsv') -->
<!-- save_data = FALSE -->
<!-- save_file = file -->
<!-- load_data = TRUE -->
<!-- load_file = file -->

<!-- # Assess bias (if load data is true it will load .tsv of data_bias) -->
<!-- bias_correct = Model_bias_correct(n_subjects = n_subjects, -->
<!--                                        set_seed = set_seed, -->
<!--                                        n_blocks = n_blocks, -->
<!--                                        perc_forced = perc_forced, -->
<!--                                        blocks_per_task = blocks_per_task, -->
<!--                                        dist_list = dist_list, -->
<!--                                        model = model, -->
<!--                                        parameters = parameters, -->
<!--                                        init_values = init_values, -->
<!--                                        shrink_distance_vec = shrink_distance_vec, -->
<!--                                        save_data = save_data, -->
<!--                                        save_file = save_file, -->
<!--                                        load_data = load_data, -->
<!--                                        load_file = load_file) -->
<!-- data_choice = bias_correct$data_bias_correct -->
<!-- ``` -->

<!-- #### Fixed parameters -->

<!-- ```{r} -->
<!-- # Steps in which to loop over each parameter -->
<!-- steps_alpha0 = 0.3 -->
<!-- steps_alpha1 = 0.7 -->
<!-- steps_temperature = 7 -->
<!-- steps_policy = 'softmax' -->
<!-- steps_interdep = 0.5 -->

<!-- # Get all combinations of parameters -->
<!-- parameters = data.table(expand.grid(steps_alpha0, -->
<!--                                     steps_alpha1, -->
<!--                                     steps_temperature, -->
<!--                                     steps_policy, -->
<!--                                     steps_interdep)) -->
<!-- colnames(parameters) = c('alpha0', -->
<!--                          'alpha1', -->
<!--                          'temperature', -->
<!--                          'choice_policy', -->
<!--                          'interdep') -->

<!-- # Add constant parameters -->
<!-- parameters$reward_space_ub = reward_space_ub -->

<!-- # Parameters for bias assessment -->
<!-- shrink_distance_vec = round(seq(0,100/6, length.out = 50), 2) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Set model for simulation -->
<!-- model = 'Pedlr_interdep' -->

<!-- # Parameters to save and load data output -->
<!-- file = file.path(derivatives_path, 'shrinkage_simulation_pedlr_fc30.tsv') -->
<!-- save_data = FALSE -->
<!-- save_file = file -->
<!-- load_data = TRUE -->
<!-- load_file = file -->

<!-- # Assess bias (if load data is true it will load .tsv of data_bias) -->
<!-- bias_correct = Model_bias_correct(n_subjects = 100, -->
<!--                                   set_seed = set_seed, -->
<!--                                   n_blocks = n_blocks, -->
<!--                                   perc_forced = perc_forced, -->
<!--                                   blocks_per_task = blocks_per_task, -->
<!--                                   dist_list = dist_list, -->
<!--                                   model = model, -->
<!--                                   parameters = parameters, -->
<!--                                   init_values = init_values, -->
<!--                                   shrink_distance_vec = shrink_distance_vec, -->
<!--                                   save_data = save_data, -->
<!--                                   save_file = save_file, -->
<!--                                   load_data = load_data, -->
<!--                                   load_file = load_file) -->
<!-- data_choice = bias_correct$data_bias_correct -->
<!-- bias_correct$plot -->
<!-- ``` -->

<!-- #### Prepare data for plotting -->

<!-- ```{r} -->
<!-- data_balance = subset(data_choice, comp == '1v2') -->
<!-- data_balance = select(data_balance, -c(comp, perc_correct)) -->
<!-- data_balance$corr_1v2 = subset(data_choice, comp == '1v2')$perc_correct -->
<!-- data_balance$corr_2v3 = subset(data_choice, comp == '2v3')$perc_correct -->
<!-- data_balance$corr_1v3 = subset(data_choice, comp == '1v3')$perc_correct -->
<!-- data_balance$balance = data_balance$corr_2v3 - data_balance$corr_1v2 -->
<!-- # Balanced normalized with average correctness -->
<!-- data_balance$rel_balance = data_balance$balance / (data_balance$corr_1v3 - 0.5) -->

<!-- data_plot = data_balance -->
<!-- data_plot = ddply(data_plot,  -->
<!--                    .(task_version, distance_shrinkage), -->
<!--                    summarize, -->
<!--                    mean_corr_1v2 = mean(corr_1v2), -->
<!--                    mean_corr_2v3 = mean(corr_2v3), -->
<!--                    mean_corr_1v3 = mean(corr_1v3), -->
<!--                    mean_balance = mean(balance), -->
<!--                    mean_rel_balance = mean(rel_balance)) -->
<!-- data_plot$distance_shrinkage = as.factor(data_plot$distance_shrinkage) -->
<!-- data_plot$task_version = as.factor(data_plot$task_version) -->
<!-- ``` -->


<!-- ##### Look at gradient of 1v2/2v3 correctness in dependence of shrinkage -->

<!-- Balance > 0: Higher dist higher correctness -->
<!-- Balance < 0: Lower dist higher correctness -->

<!-- ```{r} -->
<!-- p = ggplot(data_plot, aes(x = distance_shrinkage, y = mean_balance)) + -->
<!--   geom_point(size=0.5) + -->
<!--   #stat_summary(fun = 'mean', geom = 'point', size = 1, color = 'red') + -->
<!--   geom_vline(xintercept = as.factor(100/6), linetype='dashed', color='red') + -->
<!--   facet_wrap(~task_version) -->

<!-- p -->
<!-- ``` -->

<!-- ##### Look at gradient of 1v2/2v3 correctness in dependence of shrinkage with penalty -->

<!-- Value escalates the closer 1v3 gets to chance level (0.5) -->

<!-- ```{r} -->
<!-- p = ggplot(data_plot, aes(x = distance_shrinkage, y = mean_rel_balance)) + -->
<!--   geom_point(size=0.5) + -->
<!--   #stat_summary(fun = 'mean', geom = 'point', size = 1, color = 'red') + -->
<!--   scale_x_discrete(breaks=shrink_distance_vec[seq(1, length(seq(0,100/6, length.out=50)), by=5)]) + -->
<!--   geom_vline(xintercept = as.factor(100/6), linetype='dashed', color='red') + -->
<!--   facet_wrap(~task_version) -->

<!-- p -->
<!-- ``` -->
