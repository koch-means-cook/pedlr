---
title: "Simulation Analysis"
format: html
editor: source
---

# Setup

```{r}
library(here)
library(ggplot2)
library(data.table)
library(magrittr)
library(parallel)

base_path = here::here()

source(file.path(base_path, 'code', 'utils', 'Add_comp.R',
                 fsep = .Platform$file.sep))
source(file.path(base_path, 'code', 'utils', 'Get_running_avg.R',
                 fsep = .Platform$file.sep))
```

# Simulation results: `surprise` model

```{r}
# Load data
# Get paths of files to load
pattern = file.path(base_path,
                    'derivatives',
                    'simulation',
                    'modelsim_*0*model-surprise.tsv')
files = Sys.glob(pattern)
# Function to load text files (.tsv)
Load_tsv = function(file_path){
  tsv = data.table::fread(file_path,
                          sep = '\t',
                          na.strings = 'n/a')
  return(tsv)
}
# Get list of all text files using parallel processing
data_list = parallel::mclapply(X = files,
                               FUN = Load_tsv,
                               mc.cores = 4)
# Bind individual list entries (loaded text files) to single data frame
# (using optimized bind function by data.table package)
data = data.table::rbindlist(data_list)
```

```{r}
# Organize data table
data = data %>%
  # Rename "participants" column to avoid confusion (not real participant data, 
  # but used design is tied to participant)
  setnames(old = 'participant_id',
           new = 'design_base',
           skip_absent = TRUE) %>%
  # Set PE for not updated bandits to NA
  .[model_choice_option == 1, ':='(pe_b_2 = NA,
                                   pe_b_3 = NA)] %>%
  .[model_choice_option == 2, ':='(pe_b_1 = NA,
                                   pe_b_3 = NA)] %>%
  .[model_choice_option == 3, ':='(pe_b_1 = NA,
                                   pe_b_2 = NA)] %>%
  # Add ID for unique parameter combinations
  .[, para_id := paste0(x1,x2,x3,x4)] %>%
  Add_comp(.) %>%
  # Get side of model choice
  .[model_choice_side == 1, model_choice_side_rl := 'left'] %>%
  .[model_choice_side == 2, model_choice_side_rl := 'right'] %>%
  # Set correct choice by selecting (on average) higher outcome bandit
  .[, correct_choice := if(option_left > option_right) 'left' else 'right',
    by = c('design_base',  'para_id', 'run', 'trial')] %>%
  .[, correct := correct_choice == model_choice_side_rl]
```

```{r}
# Use analysis of rare-outcome-impact (could be implemented during loading of single file to speed things up)
# Make sure we only include choices in 1v2 comps when calculating prob of choosing 2
data_ii = data %>%
  .[comp != '1v2' | trial_type != 'choice', correct_choice := NA,
    by = c('design_base', 'para_id', 'run')] %>%
  # Get running averages
  .[, ':='(avg_1_running = Get_running_avg(choice_option = model_choice_option,
                                           choice_outcome = model_outcome,
                                           stim = 1),
           avg_2_running = Get_running_avg(choice_option = model_choice_option,
                                           choice_outcome = model_outcome,
                                           stim = 2),
           avg_3_running = Get_running_avg(choice_option = model_choice_option,
                                           choice_outcome = model_outcome,
                                           stim = 3)),
    by = c('design_base', 'para_id', 'run')]

# Allocate data holding +-5 trials from rare outcome of bandit 2
window_data = data.table()

# Function to get data slice +-5 trials from rare outcome of bandit 2
Windowrize = function(data,
                      index_rare,
                      window_size){
  result = data[seq(max(index_rare - window_size + 1, 1),
                    index_rare + window_size), ]
  result$window_center = data$trial[index_rare]
  result$window_relative = seq(max(index_rare - window_size + 1, 1),
                               index_rare + window_size) - index_rare
  result[window_relative == 0]$correct_choice = NA
  
  result$window_center = as.factor(result$window_center)
  result$window_relative = as.factor(result$window_relative)
  return(result)
}

# i_paras = '0.10.1-10NA'
# i_id = '09RI1ZH'
# i_run = '1'

# Delete all parameter combinations in which l == u (thats RW)
data_ii = data_ii[!x1 == x2,] %>%
  .[design_base %in% unique(data_ii$design_base)[1:5], ]

# For each Parameters combination, participant & run
for(i_paras in unique(data_ii$para_id)){
  message(paste0(i_paras, '...'))
  for(i_id in unique(data_ii$design_base)){
    message(paste0('   ', i_id, '...'))
    for(i_run in unique(data_ii$run)){
      message(paste0('      ', i_run, '...'))
      
      # Select data
      temp_data = data_ii[para_id == i_paras &
                            design_base == i_id &
                            run == i_run]
      
      # Get all trials where rare outcomes were obtained
      idx_chosen_rare_outcome = which(temp_data$is_rare == 1 &
                                        # CHANGE: I also allow rare outcomes that came from forced choices
                                        temp_data$trial_type %in% c('choice', 'forced') &
                                        temp_data$model_choice_option == 2)
      # For each of the rare-outcome trials
      for(rare_count in seq(1,length(idx_chosen_rare_outcome))){
        # Get data slice
        temp = Windowrize(data = temp_data,
                          index_rare = idx_chosen_rare_outcome[rare_count],
                          window_size = 3) %>%
          .[, window_relative := factor(window_relative, levels = unique(sort(window_relative)))]
        # Add count of the rare outcome
        temp$i_rare = rare_count
        # Fuse data for each participant & run
        window_data = rbind(window_data, temp)
      }
    }
  }
}


# Summarize data
window_data_run = window_data %>%
  # Eliminate windows which extended across trial boundaries (<1 or >240)
  .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
  .[!(relative_trial < 1 | relative_trial > 240),] %>%
  # Sort by relative window
  .[order(rank(design_base), rank(run), rank(window_relative)),] %>%
  # Get mean accuracy across all relative window positions (-2 to +3)
  .[, .(mean_accuracy = mean(correct, na.rm = TRUE),
        n_data = sum(!is.na(correct))),
    by = c('para_id', 'design_base','run', 'window_relative')]

# Get mean across runs
window_data_participant = window_data_run %>%
  .[, .(accuracy = mean(mean_accuracy, na.rm = TRUE)),
    by = c('para_id', 'design_base', 'window_relative')]
  
# Get age group specific mean and sd
window_data_group = window_data_participant %>%
  .[, .(mean_accuracy = mean(accuracy, na.rm = TRUE),
        sd_accuracy = sd(accuracy, na.rm = TRUE)),
    by = c('para_id', 'window_relative')] %>%
  .[order(rank(group), rank(window_relative)),]

```

