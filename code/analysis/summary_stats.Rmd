---
title: "Summary Stats"
output:
  html_document:
    toc: yes
    self_contained: true
    toc_float:
      collapsed: true
      smooth_scroll: false
    toc_depth: 3
    number_sections: False
    highlight: pygments
    theme: cosmo
    code_folding: "hide"
    df_print: paged
    fig_caption: true
  pdf_document:
    toc: yes
    fig_caption: true
    latex_engine: xelatex
fig.align: "center"
header-includes:
  - \usepackage{fontspec}
  - \setmainfont{AgfaRotisSansSerif}
email: koch@mpib-berlin.mpg.de
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(data.table)
library(here)
library(magrittr)
library(ggplot2)
library(viridis)
library(binhf)
```

```{r}
# Get directory of repository
base_path = here::here()

# Load pre-written functions
source_path = file.path(base_path, 'code', 'utils',
                        fsep = .Platform$file.sep)
source_files = list.files(source_path, pattern = "[.][rR]$",
                          full.names = TRUE, recursive = TRUE)
invisible(lapply(source_files, function(x) source(x)))
```

```{r}
# Load data
data = Load_data() %>%
  Add_comp(.) %>%
  .[, task_version := as.factor(task_version)]

# get number of participants (to adjust figure height)
n_participants = length(unique(data$participant_id))
```

# Data quality

## Errors in forced choices

```{r}
# Summary: Mistakes on forced choices
check_fce = data %>%
  .[trial_type == 'forced',] %>%
  .[, forced_error := error] %>%
  .[, .(n_forced = length(forced),
        n_error = sum(as.numeric(forced_error))), by = 'participant_id'] %>%
  .[, perc_forced_error := round((n_error/n_forced) * 100, 2)] %>%
  .[, count := seq(.N), by = n_error]

# Plot errors for each participant
p_fce = ggplot(data = check_fce,
               aes(x = n_error,
                   y = count,
                   label = participant_id)) +
  geom_label() +
  labs(x = 'Number of errors during forced choices',
       y = 'N') +
  scale_x_continuous(limits = c(0,max(check_fce$n_error)),
                     breaks = seq(max(check_fce$n_error, by = 1))) +
  scale_y_continuous(limits = c(1,max(check_fce$count)),
                     breaks = seq(max(check_fce$count, by = 1))) +
  theme()
p_fce
```

## Number of time out trials

```{r}
check_tot = data %>%
  .[trial_type %in% c('choice', 'forced'),] %>%
  .[, .(n_timeout = sum(as.logical(timeout))),
        by = 'participant_id'] %>%
  .[, count := seq(.N), by = n_timeout]

# Plot errors for each participant
p_tot = ggplot(data = check_tot,
               aes(x = n_timeout,
                   y = count,
                   label = participant_id)) +
  geom_label() +
  labs(x = 'Number of timeouts across all trials',
       y = 'N') +
  scale_x_continuous(limits = c(0,max(check_tot$n_timeout)),
                     breaks = seq(max(check_tot$n_timeout, by = 1))) +
  scale_y_continuous(limits = c(1,max(check_tot$count)),
                     breaks = seq(max(check_tot$count, by = 1))) +
  theme()
p_tot
```

# Estimation

## Estimation track

```{r, fig.height=0.75*n_participants, out.width='100%'}
check_est = data %>%
  .[, forced_rare := as.numeric(as.logical(is_rare) & trial_type == 'forced' & (comp == '1v2' | comp == '2v3'))] %>%
  .[!is.na(est_1_reward),] %>%
  .[, est_trial := seq(.N), by = c('participant_id', 'task_version')] %>%
  data.table::melt(.,
                   id.vars = c('participant_id',
                               'task_version',
                               'est_trial',
                               'forced_rare'),
                   measure.vars = c('est_1_reward',
                                    'est_1_range',
                                    'est_2_reward',
                                    'est_2_range',
                                    'est_3_reward',
                                    'est_3_range')) %>%
  .[, est_stim := substr(variable, 5, 5)] %>%
  .[, type := substr(variable, 7, 9)] %>%
  .[type == 'rew', type := 'reward'] %>%
  .[type == 'ran', type := 'range'] %>%
  data.table::dcast(., participant_id + task_version + est_trial + forced_rare + est_stim ~ type, value.var = 'value')

# Get true mean of options
rewards = data %>%
  .[, c('participant_id', 'task_version', 'option_left', 'reward_stim_1', 'option_right', 'reward_stim_2')]
rewards_left = rewards[, c('participant_id', 'task_version', 'option_left', 'reward_stim_1')] %>%
  setnames(., c('option_left', 'reward_stim_1'), c('est_stim', 'reward'))
rewards_right = rewards[, c('participant_id', 'task_version', 'option_right', 'reward_stim_2')] %>%
  setnames(., c('option_right', 'reward_stim_2'), c('est_stim', 'reward'))
true_means = rbind(rewards_left, rewards_right) %>%
  .[, .(mean = mean(reward)), by = c('participant_id', 'task_version', 'est_stim')]

p_est = ggplot(data = check_est,
               aes(x = est_trial,
                   y = reward,
                   color = est_stim)) +
  geom_hline(data = true_means,
             aes(yintercept = mean),
             linetype = 'dashed') +
  geom_ribbon(aes(ymin = reward - range,
                  ymax = reward + range),
              alpha = 0.3) +
  geom_point(size = 0.8) +
  geom_path() +
  labs(x = 'Estimation Trial',
       y = 'Estimate') +
  facet_grid(participant_id ~ task_version + est_stim) +
  scale_color_viridis(option = 'D', discrete = TRUE) +
  theme(legend.position = 'none')
p_est
```

## Estimates after rare

```{r, fig.height=0.75*n_participants, out.width='100%'}
p_ear = ggplot(data = check_est,
               aes(x = est_trial,
                   y = reward)) +
  geom_hline(data = true_means,
             aes(yintercept = mean),
             linetype = 'dashed') +
  geom_ribbon(aes(ymin = reward - range,
                  ymax = reward + range),
              alpha = 0.3) +
  geom_path() +
  geom_point(aes(color = as.factor(forced_rare)),
             size = 0.8) +
  labs(x = 'Estimation Trial',
       y = 'Estimate') +
  facet_grid(participant_id ~ task_version + est_stim) +
  scale_color_viridis(option = 'D', discrete = TRUE) +
  theme(legend.position = 'top')
p_ear
```

## Estimating difference from truth

```{r, fig.height=0.75*n_participants, out.width='100%'}
true_means$est_stim = as.factor(true_means$est_stim)
# Merge true means with estimation
check_est_diff = check_est %>%
  data.table::merge.data.table(.,
                               true_means,
                               by = c('participant_id',
                                      'task_version',
                                      'est_stim')) %>%
  # Get difference between estimation and true mean
  .[, diff_from_true := reward - mean]

p_est_diff = ggplot(data = check_est_diff,
                    aes(x = est_trial,
                        y = diff_from_true,
                        color = as.factor(task_version))) +
  geom_hline(yintercept = 0,
             linetype = 'dashed') +
  geom_path() +
  scale_color_viridis(option = 'D', discrete = TRUE) +
  facet_grid(participant_id ~ est_stim) +
  theme(legend.position = 'top')
p_est_diff
```

## Mean difference from truth in estimation

```{r, out.width='100%'}
p_est_diff = ggplot(data = check_est_diff,
                    aes(x = est_trial,
                        y = diff_from_true,
                        color = est_stim)) +
  geom_hline(yintercept = 0,
             linetype = 'dashed') +
  geom_path(alpha = 0.3, aes(group = participant_id)) +
  stat_summary(fun = 'mean', geom = 'line', size = 1.5) +
  scale_color_viridis(option = 'D', discrete = TRUE) +
  facet_grid(task_version~ est_stim) +
  theme(legend.position = 'top')
p_est_diff
```

# RT

## RT (median)

```{r, fig.height=0.75*n_participants, out.width='100%'}
check_rt = data %>%
  .[, trial := seq(.N),
    by = c('participant_id', 'task_version')] %>%
  .[timeout == FALSE, ] %>%
  data.table::melt(.,
                   id.vars = c('participant_id',
                               'task_version',
                               'trial',
                               'trial_type',
                               'comp'),
                   measure.vars = 'rt')
p_rt = ggplot(data = check_rt,
       aes(x = comp,
           y = value)) +
  geom_jitter(width = 0.1,
              size = 0.2) +
  stat_summary(geom = 'path',
               fun = 'median',
               color = 'black',
               size = 0.5,
               group = 'participant_id') +
  stat_summary(geom = 'point',
               fun = 'median',
               color = 'black',
               fill = 'white',
               shape = 21,
               size = 2) +
  labs(x = 'Trial Type',
       y = 'RT') +
  facet_grid(participant_id ~ trial_type + task_version)
p_rt
```

## RT difference 1v2 and 2v3 {.tabset}

### Line plot

```{r, out.width='100%', fig.show='hold'}
check_rt_diff = check_rt %>%
  .[, .(median_rt = median(value),
        mean_rt = mean(value)),
    by = c('participant_id', 'task_version', 'trial_type', 'comp')] %>%
  .[comp %in% c('1v2', '2v3')]

p_rtd_median = ggplot(data = check_rt_diff,
                      aes(x = comp,
                          y = median_rt)) +
  geom_point() +
  geom_line(aes(group = participant_id)) +
  labs(title = 'Median') +
  facet_wrap(~trial_type + task_version, nrow = 1)
p_rtd_median

p_rtd_mean = ggplot(data = check_rt_diff,
                    aes(x = comp,
                        y = mean_rt)) +
  geom_point() +
  geom_line(aes(group = participant_id)) +
  labs(title = 'Mean') +
  facet_wrap(~trial_type + task_version, nrow = 1)
p_rtd_mean
```

Time-outs excluded from calculation.

### Difference

```{r, out.width='100%', fig.show='hold'}
check_rt_diff_comp = check_rt_diff %>%
  data.table::dcast(participant_id + task_version + trial_type ~ comp,
                    value.var = c('median_rt', 'mean_rt')) %>%
  .[, ':='(median_1v2m2v3 = median_rt_1v2 - median_rt_2v3,
           mean_1v2m2v3 = mean_rt_1v2 - mean_rt_2v3)] %>%
  .[, task_version := as.factor(task_version)]

p_rtc_median = ggplot(data = check_rt_diff_comp,
                      aes(x = task_version,
                          y = median_1v2m2v3)) +
  geom_hline(yintercept = 0,
             linetype = 'dashed') +
  geom_point() +
  scale_y_continuous(limits = c(-max(abs(check_rt_diff_comp$median_1v2m2v3)),
                                max(abs(check_rt_diff_comp$median_1v2m2v3)))) +
  labs(title = 'Difference Median (1v2 - 2v3)') +
  facet_wrap(~trial_type)
p_rtc_median

p_rtc_mean = ggplot(data = check_rt_diff_comp,
                      aes(x = task_version,
                          y = mean_1v2m2v3)) +
  geom_hline(yintercept = 0,
             linetype = 'dashed') +
  geom_point() +
  scale_y_continuous(limits = c(-max(abs(check_rt_diff_comp$mean_1v2m2v3)),
                                max(abs(check_rt_diff_comp$mean_1v2m2v3)))) +
  labs(title = 'Difference Mean (1v2 - 2v3)') +
  facet_wrap(~trial_type)
p_rtc_mean
```

# Correctness

## Percent of non-optimal choices

```{r, fig.height=0.75*n_participants, out.width='100%'}
check_noc = data %>%
  .[trial_type == 'choice',] %>%
  .[, correct_choice := if(option_left > option_right) 'left' else 'right',
    by = c('participant_id', 'task_version', 'trial')] %>%
  .[, correct := correct_choice == choice] %>%
  # Get percentage of correct choices (exclude timeouts from overall trials)
  .[, .(perc_correct = sum(as.numeric(correct), na.rm = TRUE) / length(which(!is.na(as.numeric(correct))))),
    by = c('participant_id', 'task_version', 'comp')]

p_noc = ggplot(data = check_noc,
               aes(x = comp,
                   y = perc_correct,
                   group = participant_id)) +
  geom_line() +
  geom_point() +
  labs(x = '%-correct',
       y = 'Comparison') +
  facet_grid(participant_id ~ task_version)
p_noc
```

## Difference between comparisons including asymmetric stimulus {.tabset}

### Line plot

```{r, out.width='100%'}
check_noc_crit = check_noc %>%
  .[comp %in% c('1v2', '2v3'),]

p_noc_diff_comp_line = ggplot(data = check_noc_crit,
                              aes(x = comp,
                                  y = perc_correct)) +
  geom_point() +
  geom_line(aes(group = participant_id)) +
  facet_wrap(~task_version)
p_noc_diff_comp_line
```

### Difference

```{r, out.width='100%'}
check_noc_diff = check_noc %>%
  # Only select critical comparisons
  .[comp %in% c('1v2', '2v3'),] %>%
  data.table::dcast(participant_id + task_version ~ paste('mean_', comp, sep = ''), value.var = 'perc_correct') %>%
  .[, diff_1v2m2v3 := mean_1v2 - mean_2v3]

p_noc_diff_comp_diff = ggplot(data = check_noc_diff,
                         aes(x = task_version,
                             y = diff_1v2m2v3)) +
  geom_hline(yintercept = 0,
             linetype = 'dashed') +
  geom_point() +
  scale_y_continuous(limits = c(-max(abs(check_noc_diff$diff_1v2m2v3)),
                                max(abs(check_noc_diff$diff_1v2m2v3)))) +
  labs(title = 'Difference between crit comparisons (1v2 - 2v3)')
p_noc_diff_comp_diff
```

## Non-optimal between run 1 and 2

```{r, out.width='100%'}
p_noc_diff_run = ggplot(data = check_noc,
                        aes(x = task_version,
                            y = perc_correct,
                            group = participant_id)) +
  geom_point() +
  geom_line() +
  facet_wrap(~comp)
p_noc_diff_run
```
