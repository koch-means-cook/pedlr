---
title: "Results 01"
output:
  html_document:
    toc: yes
    self_contained: true
    toc_float:
      collapsed: true
      smooth_scroll: false
    toc_depth: 3
    number_sections: False
    highlight: pygments
    theme: cosmo
    code_folding: "hide"
    df_print: paged
    fig_caption: true
  pdf_document:
    toc: yes
    fig_caption: true
    latex_engine: xelatex
fig.align: "center"
header-includes:
  - \usepackage{fontspec}
  - \setmainfont{AgfaRotisSansSerif}
email: koch@mpib-berlin.mpg.de
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(data.table)
library(here)
library(magrittr)
library(ggplot2)
library(viridis)
library(binhf)
library(pwr)
library(knitr)
library(kableExtra)
library(sdamr)
library(gghalves)
library(lme4)
library(emmeans)
library(papeR)
library(ggtext)
library(MASS)
```

```{r, message=FALSE}
# Get directory of repository
base_path = here::here()

# Load pre-written functions
source_path = file.path(base_path, 'code', 'utils',
                        fsep = .Platform$file.sep)
source_files = list.files(source_path, pattern = "[.][rR]$",
                          full.names = TRUE, recursive = TRUE)
invisible(lapply(source_files, function(x) source(x)))

# Get plot colors/linetypes
custom_guides = Get_plot_guides()
```

```{r}
# Load data
data = Load_data() %>%
  Apply_exclusion_criteria(., choice_based_exclusion = TRUE) %>%
  Add_comp(.) %>%
  .[, run := as.factor(run)]

# get number of participants (to adjust figure height)
n_participants = length(unique(data$participant_id))
```

```{r}
file = file.path('~', 'Desktop', 'pedlr_data.tsv',
                 fsep = .Platform$file.sep)
data.table::fwrite(data, file = file, na = 'n/a', sep = '\t', row.names = FALSE)
```


---

# Overall performance

```{r, fig.height=0.75*n_participants, out.width='100%'}
# Percentage of optimal choices
check_noc = data %>%
  .[, trial := seq(.N),
    by = c('participant_id', 'run')] %>%
  .[trial_type == 'choice',] %>%
  .[, correct_choice := if(option_left > option_right) 'left' else 'right',
    by = c('participant_id', 'run', 'trial')] %>%
  .[, correct := correct_choice == choice] %>%
  # Get percentage of correct choices (exclude timeouts from overall trials)
  .[, .(perc_correct = sum(as.numeric(correct), na.rm = TRUE) / length(which(!is.na(as.numeric(correct))))),
    by = c('participant_id', 'group', 'run', 'comp')]
```

## Plot

```{r}
data_plot = Prepare_data_for_plot(check_noc)
p_noc_diff_comp_line = ggplot(data = data_plot,
                              aes(x = comp,
                                  y = perc_correct,
                                  color = group,
                                  fill = group)) +
  geom_point(size = 0.2,
             position = position_jitterdodge(dodge.width = 0.3,
                                             jitter.width = 0.2,
                                             jitter.height = 0)) +
  geom_boxplot(width = 0.15,
               color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = 0.3),
               show.legend = FALSE) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = 0.3)) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides) +
  facet_grid( ~ run) +
  theme(strip.text.y = element_text(angle = 0),
        legend.position = 'none')
Neurocodify_plot(p_noc_diff_comp_line)
```

## Stats

```{r}
# Assure data types
check_noc$participant_id = as.factor(check_noc$participant_id)
check_noc$group = as.factor(check_noc$group)
check_noc$run = as.factor(check_noc$run)
check_noc$comp = as.factor(check_noc$comp)
check_noc$perc_correct = as.numeric(check_noc$perc_correct)

# LME
lme_noc = lme4::lmer(data = check_noc,
                     perc_correct ~ group * run * comp + (1 | participant_id))
papeR::prettify(Anova(lme_noc))
```

### Main effect run

```{r}
emmeans::emmeans(lme_noc,
                 pairwise ~ run)
```

### Main effect comp

```{r}
emmeans::emmeans(lme_noc,
                 pairwise ~ comp)
```

---

```{r}
bla = data %>%
  .[, trial := seq(.N),
    by = c('participant_id', 'run')] %>%
  .[trial_type == 'choice', correct := if(option_left > option_right) 'left' else 'right',
    by = c('participant_id', 'run', 'trial')] %>%
  .[trial_type == 'forced', correct := forced,
    by = c('participant_id', 'run', 'trial')] %>%
  # Exclude time-out trials
  .[!is.na(outcome), correct_choice := choice == correct,
    by = c('participant_id', 'run', 'trial')]

bla_mean_correct = bla %>%
  .[trial_type == 'choice', ] %>%
  # Average over runs
  .[, .(mean_correct = mean(correct_choice, na.rm = TRUE),
        sd_correct = sd(correct_choice, na.rm = TRUE)),
    by = c('participant_id', 'group', 'run', 'comp')] %>%
  # Sort for easier checks
  .[order(rank(comp)),] %>%
  # Wide format to calculate differences
  data.table::dcast(participant_id + group + run ~ paste0('comp_', comp),
                    value.var = 'mean_correct') %>%
  # Get difference between critical comparisons
  .[, bandit_effect := comp_2v3 - comp_1v2] %>%
  # Average over runs
  .[, .(mean_bandit_effect = mean(bandit_effect, na.rm = TRUE)),
    by = c('participant_id', 'group')] %>%
  # Convert group to factor
  .[, ':='(group = as.factor(group),
           participant_id = as.factor(participant_id))]
```

## Stats

```{r}
# Test difference in older adults against 0
t.test(bla_mean_correct[group == 'older']$mean_bandit_effect)
# Test difference in younger adults against 0
t.test(bla_mean_correct[group == 'younger']$mean_bandit_effect)
# Compare age groups
t.test(bla_mean_correct[group == 'older']$mean_bandit_effect,
       bla_mean_correct[group == 'younger']$mean_bandit_effect)

# Exclusion of "outliers"
outlier_excl = bla_mean_correct[!participant_id %in% c('456LJD0', '8TYYUVQ')]
t.test(outlier_excl[group == 'older']$mean_bandit_effect,
       outlier_excl[group == 'younger']$mean_bandit_effect)
```

## Plot

```{r}
data_plot = Prepare_data_for_plot(bla_mean_correct) 

nudge_with = 0.15

p = ggplot(data = data_plot,
           aes(x = group,
               y = mean_bandit_effect,
               color = group,
               fill = group)) +
  geom_point(position = sdamr::position_jitternudge(nudge.x = -nudge_with,
                                                    jitter.width = 0.05,
                                                    jitter.height = 0,
                                                    seed = 666),
             alpha = 0.5) +
  gghalves::geom_half_violin(side = 'r',
                             width = 0.3,
                             position = position_nudge(x = nudge_with)) +
  geom_boxplot(outlier.shape = NA,
               color = 'black',
               width = 0.1) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               show.legend = FALSE) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides)
  
Neurocodify_plot(p)
```

```{r}
data_plot = Prepare_data_for_plot(outlier_excl) 

nudge_with = 0.15

p = ggplot(data = data_plot,
           aes(x = group,
               y = mean_bandit_effect,
               color = group,
               fill = group)) +#
  geom_hline(yintercept = 0,
             size = 0.5) +
  geom_point(position = sdamr::position_jitternudge(nudge.x = -nudge_with,
                                                    jitter.width = 0.05,
                                                    jitter.height = 0,
                                                    seed = 666),
             alpha = 0.5) +
  gghalves::geom_half_violin(side = 'r',
                             width = 0.3,
                             position = position_nudge(x = nudge_with),
                             color = NA) +
  geom_boxplot(outlier.shape = NA,
               color = 'black',
               width = 0.1) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 2,
               stroke = 0.5,
               show.legend = FALSE) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides) +
  scale_y_continuous(limits = c(-0.2, 0.5),
                     breaks = seq(-0.2, 0.4, by = 0.2)) +
  theme(legend.position = 'none')
  
Neurocodify_plot(p)
```

## Robust regression approach {.tabset}

### Standard OLS

#### Regression model

```{r}
# Standard OLS
ols = lm(mean_bandit_effect ~ 1 + group,
         data = bla_mean_correct)
summary(ols)
```

#### Plot residuals, QQ, weighting, and leverage

```{r}
# Plot residuals, QQ, weighting, and leverage
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(ols, las = 1)
```

#### Display by cooks distance

```{r}
# Display values with large cook's distance
cooks_d <- cooks.distance(ols)
r <- stdres(ols)
a <- cbind(bla_mean_correct, cooks_d, r)
# Conventional cut-off (https://stats.oarc.ucla.edu/r/dae/robust-regression/)
cutoff = 4/nrow(bla_mean_correct)
# Only absolute residuals matter
a = a %>%
  .[, ':='(abs_r = abs(r),
           cutoff = cooks_d > cutoff)] %>%
  .[order(rank(-abs_r))]
a
```

### Robust regression

Both robust regression approaches agree in significant group effect.

#### Robust Regression with Huber weights

```{r}
# Robust Regression model (huber weights)
rr.huber = MASS::rlm(mean_bandit_effect ~ 1 + group,
                     data = bla_mean_correct)
bla = summary(rr.huber)
bla

# Look at weights created by RR (low weights = "outlier-y behavior")
hweights = bla_mean_correct %>%
  .[, ':='(resid = rr.huber$resid,
           weight = rr.huber$w)] %>%
  # Sort by weight
  .[order(rank(weight)),]
hweights
```

```{r}
out = data.table(bla$coefficients)

plot_t = data.table(x = seq(-5,5, by = 0.01),
                    y = dt(seq(-5,5, by = 0.01), df=bla$df[2]))
 p = ggplot(data = plot_t,
       aes(x = x,
           y = y)) +
  geom_path() +
   # Mark cut-offs
  geom_vline(xintercept = qt(c(.025, .975), df = bla$df[2]),
             linetype = 'dashed') +
   # Mark t-value of group statistic
  geom_vline(xintercept = out$`t value`[2],
             color = 'red') +
   labs(x = 't-Value',
        y = 'Density',
        main = 't-Distribution for group effect') +
   scale_y_continuous(expand = c(0,0))
 Neurocodify_plot(p) +
   theme(panel.grid = element_blank())
```


#### Robust Regression with Bisquare weights

```{r}
# Robust regression (bisquare weights)
rr.bisquare = MASS::rlm(mean_bandit_effect ~ 1 + group,
                     data = bla_mean_correct,
                     psi = psi.bisquare)
bla = summary(rr.bisquare)
bla

# Look at weights created by RR (low weights = "outlier-y behavior")
bweights = bla_mean_correct %>%
  .[, ':='(resid = rr.bisquare$resid,
           weight = rr.bisquare$w)] %>%
  # Sort by weight
  .[order(rank(weight)),]
bweights
```

```{r}
out = data.table(bla$coefficients)

plot_t = data.table(x = seq(-5,5, by = 0.01),
                    y = dt(seq(-5,5, by = 0.01), df=bla$df[2]))
 p = ggplot(data = plot_t,
       aes(x = x,
           y = y)) +
  geom_path() +
   # Mark cut-offs
  geom_vline(xintercept = qt(c(.025, .975), df = bla$df[2]),
             linetype = 'dashed') +
   # Mark t-value of group statistic
  geom_vline(xintercept = out$`t value`[2],
             color = 'red') +
   labs(x = 't-Value',
        y = 'Density',
        main = 't-Distribution for group effect') +
   scale_y_continuous(expand = c(0,0))
 Neurocodify_plot(p) +
   theme(panel.grid = element_blank())
```


---

# Risk aversion (proportion of M choices)

```{r}
check_risk = data %>%
  Add_comp() %>%
  # Only take free choices
  .[trial_type == 'choice',] %>%
  .[comp != '1v3',] %>%
  .[, .(n_overall = .N,
        n_choice_2 = length(which(option_choice == 2))),
    by = c('participant_id', 'group', 'run', 'trial_type')] %>%
  .[, perc_choice_2 := n_choice_2 / n_overall * 100]
```

## Stats

```{r}
# Assure data types
check_risk$participant_id = as.factor(check_risk$participant_id)
check_risk$group = as.factor(check_risk$group)
check_risk$run = as.factor(check_risk$run)
check_risk$trial_type = as.factor(check_risk$trial_type)
check_risk$n_overall = as.numeric(check_risk$n_overall)
check_risk$n_choice_2 = as.numeric(check_risk$n_choice_2)
check_risk$perc_choice_2 = as.numeric(check_risk$perc_choice_2)

lme_risk = lme4::lmer(data = check_risk,
           perc_choice_2 ~ group * run + (1|participant_id))
papeR::prettify(Anova(lme_risk))
```

## Plot

```{r}
data_plot = Prepare_data_for_plot(check_risk)

dodge_width = 0.3

p_risk = ggplot(data = data_plot,
                aes(x = group,
                    y = perc_choice_2,
                    color = group,
                    fill = group)) +
    geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = dodge_width/2,
                                             jitter.height = 0,
                                             seed = 666)) +
  geom_boxplot(outlier.shape = NA,
               color = 'black',
               width = dodge_width,
               position = position_dodge(width = dodge_width)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = dodge_width),
               show.legend = FALSE) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides)
Neurocodify_plot(p_risk)
```

(Whats the baseline exactly? Could there be local bubbles of comparisons that would encourage deviations fpr risk aversion?)

### Actually different from 50%?

```{r}
data_test = check_risk %>%
  # calculate mean over runs
  .[, .(mean_perc_choice_2 = mean(perc_choice_2)),
    by = c('participant_id', 'group', 'trial_type')] %>%
  # t.test against 50%
  .[, .(estimate = t.test(mean_perc_choice_2, mu = 50)$estimate,
        t = t.test(mean_perc_choice_2, mu = 50)$statistic,
        df = t.test(mean_perc_choice_2, mu = 50)$parameter,
        alpha = .05,
        alpha_corr = .05 / 2,
        p = t.test(mean_perc_choice_2, mu = 50)$p.value),
    by = 'group']

knitr::kable(data_test) %>%
  kableExtra::kable_styling()
```

---

# Effect of rare events on choice performance

```{r}
# Make sure we only include choices in 1v2 comps when calculating prob of choosing 2
bla = data %>%
  .[comp != '1v2' | trial_type != 'choice', correct_choice := NA,
    by = c('participant_id', 'run')] %>%
  # Get running averages
  .[, ':='(avg_1_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 1),
           avg_2_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 2),
           avg_3_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 3)),
    by = c('participant_id', 'run')]

# Allocate data holding +-5 trials from rare outcome of bandit 2
window_data = data.table()

#rep(NA, max(-z+wdsz, 0))

# Function to get data slice +-5 trials from rare outcome of bandit 2
Windowrize = function(data,
                      index_rare,
                      window_size){
  result = data[seq(max(index_rare - window_size + 1, 1),
                    index_rare + window_size), ]
  result$window_center = data$trial[index_rare]
  result$window_relative = seq(max(index_rare - window_size + 1, 1),
                               index_rare + window_size) - index_rare
  result[window_relative == 0]$correct_choice = NA
  
  result$window_center = as.factor(result$window_center)
  result$window_relative = as.factor(result$window_relative)
  return(result)
}

# i_id = '09RI1ZH'
# i_run = '1'

# For each participant & run
for(i_id in unique(bla$participant_id)){
  for(i_run in unique(bla$run)){
    
    # Select data
    temp_data = bla[participant_id == i_id &
                      run == i_run]
    
    # Get all trials where rare outcomes were obtained
    idx_chosen_rare_outcome = which(temp_data$is_rare == 1 &
                                      # CHANGE: I also allow rare outcomes that came from forced choices
                                      temp_data$trial_type %in% c('choice', 'forced') &
                                      temp_data$option_choice == 2)
   # For each of the rare-outcome trials
   for(rare_count in seq(1,length(idx_chosen_rare_outcome))){
    # Get data slice
     temp = Windowrize(data = temp_data,
                       index_rare = idx_chosen_rare_outcome[rare_count],
                       window_size = 3) %>%
       .[, window_relative := factor(window_relative, levels = unique(sort(window_relative)))]
     # Add count of the rare outcome
     temp$i_rare = rare_count
     # Fuse data for each participant & run
     window_data = rbind(window_data, temp)
   }
  }
}

# Summarize data
window_data_run = window_data %>%
  # Eliminate windows which extended across trial boundaries (<1 or >240)
  .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
  .[!(relative_trial < 1 | relative_trial > 240),] %>%
  # Sort by relative window
  .[order(rank(group), rank(participant_id), rank(run), rank(window_relative)),] %>%
  # Get mean accuracy across all relative window positions (-2 to +3)
  .[, .(mean_accuracy = mean(correct_choice, na.rm = TRUE),
        n_data = sum(!is.na(correct_choice))),
    by = c('participant_id', 'group', 'run', 'window_relative')]

# Get mean across runs
window_data_participant = window_data_run %>%
  .[, .(accuracy = mean(mean_accuracy, na.rm = TRUE)),
    by = c('participant_id', 'group', 'window_relative')]
  
# Get age group specific mean and sd
window_data_group = window_data_participant %>%
  .[, .(mean_accuracy = mean(accuracy, na.rm = TRUE),
        sd_accuracy = sd(accuracy, na.rm = TRUE)),
    by = c('group', 'window_relative')] %>%
  .[order(rank(group), rank(window_relative)),]
```

```{r}
avg_n_rare = window_data %>%
  # Eliminate windows which extended across trial boundaries (<1 or >240)
  .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
  .[!(relative_trial < 1 | relative_trial > 240),] %>%
  # Get number of rare outcomes collected
  .[, .(n_rare = max(i_rare)),
    by = c('participant_id', 'group', 'run')]

data_plot = Prepare_data_for_plot(avg_n_rare)

dodge_width = 0.075
jitter_width = dodge_width/2

p = ggplot(data = data_plot,
       aes(x = group,
           y = n_rare,
           color = group,
           fill = group)) +
  geom_hline(yintercept = 0,
             size = 0.5) +
  geom_point(position = position_jitternudge(jitter.width = jitter_width,
                                             jitter.height = 0,
                                             nudge.x = dodge_width + jitter_width/2,
                                             seed = 666),
             alpha = 0.5) +
  geom_boxplot(outlier.shape = NA,
               color = 'black',
               width = dodge_width/2) +
  gghalves::geom_half_violin(color = NA,
                             position = position_nudge(x = -dodge_width)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               fill = 'white',
               size = 3,
               stroke = 0.5) +
  theme(legend.position = 'none')
Neurocodify_plot(p)

```

Average number of rare outcomes in each run

```{r}
# Average rare outcomes per run
avg_n_rare_per_run = mean(avg_n_rare$n_rare)
avg_n_rare_per_run
```

Average number of free-choice LM trials immediately preceding or following a rare outcome

```{r}
# Avg n_data pre and post rare outcome
window_data_run[window_relative %in% c('-1', '1')] %>%
  .[, .(mean_n_data = mean(n_data)),
    by = c('window_relative')]
```


## Stats

```{r}
# test pre vs post trial
# younger
t.test(window_data_participant[window_relative == '-1' & group == 'younger']$accuracy,
       window_data_participant[window_relative == '1' & group == 'younger']$accuracy,
       paired = TRUE)
# older
t.test(window_data_participant[window_relative == '-1' & group == 'older']$accuracy,
       window_data_participant[window_relative == '1' & group == 'older']$accuracy,
       paired = TRUE)
# younger vs older
t.test(
  window_data_participant[window_relative == '-1' & group == 'younger']$accuracy -
    window_data_participant[window_relative == '1' & group == 'younger']$accuracy,
  window_data_participant[window_relative == '-1' & group == 'older']$accuracy -
    window_data_participant[window_relative == '1' & group == 'older']$accuracy
  )
```

```{r}
data_lme = window_data_run[window_relative %in% c('-1', '1')] %>%
  .[, group := as.factor(group)] %>%
  .[, participant_id := as.factor(participant_id)]

lme = lme4::lmer(data = data_lme,
                 mean_accuracy ~ window_relative * group * run + (1 | participant_id))
Anova(lme)
```

### Main effect: Window

```{r}
emmeans::emmeans(lme, pairwise ~ window_relative)
```

### Main effect: Run

```{r}
emmeans::emmeans(lme, pairwise ~ run)
```

### Interaction effect: Window X group

```{r}
emmeans::emmeans(lme, pairwise ~ window_relative | group)
```


## Plot

```{r}
data_plot = Prepare_data_for_plot(window_data_participant) %>%
  .[, window_relative := as.numeric(as.character(window_relative))] %>%
  .[!window_relative == 0, ]

data_plot_mean = data_plot %>%
  .[, .(accuracy = mean(accuracy),
        sem_accuracy = sd(accuracy) / sqrt(.N)),
    by = c('group', 'window_relative')]

dodge_width = 0.3

p = ggplot(data = data_plot,
       aes(x = window_relative,
           y = accuracy,
           fill = group,
           color = group,
           group = interaction(window_relative, group))) +
  geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = 0.1,
                                             jitter.height = 0,
                                             seed = 666),
             size = 0.5,
             alpha = 0.5) +
  # geom_line(aes(group = participant_id),
  #           alpha = 0.1,
  #           size = 0.5) +
  # geom_boxplot(color = 'black',
  #              outlier.shape = NA,
  #              width = dodge_width,
  #              position = position_dodge(width = dodge_width)) +
  geom_vline(xintercept = 0,
             linetype = 'dashed') +
  geom_path(data = data_plot_mean,
             size = 1,
             position = position_dodge(dodge_width),
            aes(group = group)) +
  geom_errorbar(data = data_plot_mean,
                  aes(x = window_relative,
                      y = accuracy,
                      ymin = accuracy - sem_accuracy,
                      ymax = accuracy + sem_accuracy),
                  size = 0.5,
                width = dodge_width/2,
                  position = position_dodge(dodge_width),
                color = 'black') +
  geom_point(data = data_plot_mean,
                  aes(x = window_relative,
                      y = accuracy),
                  size = 3,
                  position = position_dodge(dodge_width),
             shape = 21,
             color = 'black') +
  scale_fill_manual(values = custom_guides) +
  scale_color_manual(values = custom_guides) +
  scale_x_continuous(breaks = seq(min(data_plot$window_relative),
                                max(data_plot$window_relative))) +
  scale_y_continuous(limits = c(0,1)) +
  ggtext::geom_richtext(x = 0,
                        y = 0.1,
                        label = 'Rare outcome in Mid arm',
                        fill = 'white',
                        color = 'black',
                        angle = 90,
                        size = 3,
                        hjust = 0) +
  labs(y = 'p(Choice Mid | LM)') +
  theme(legend.position = 'top')
  
Neurocodify_plot(p) +
  theme(panel.grid = element_blank())
```

## Events between 20th and 40th percentile

```{r}
window_data_normal = data.table()
# For each participant & run
for(i_id in unique(bla$participant_id)){
  for(i_run in unique(bla$run)){
    
    # Select data
    temp_data = bla[participant_id == i_id &
                      run == i_run]
    
    # Get percentiles of second bandit for upper and lower bound
    perc = temp_data[comp %in% c('1v2', '2v3')] %>%
      .[, sample_2 := c(reward_stim_1, reward_stim_2)[which(c(option_left, option_right) == 2)],
        by = c('trial')]
    lb = quantile(perc$sample_2, prob = 0.2)
    ub = quantile(perc$sample_2, prob = 0.4)
    
    temp_data = temp_data %>%
      # Get if outcome is between specified percentiles
      .[, is_p20to40 := FALSE] %>%
      .[outcome >= lb & outcome <= ub, is_p20to40 := TRUE]
    
    # Get all trials where rare outcomes were obtained
    idx_chosen_normal_outcome = which(temp_data$is_rare == 0 &
                                        temp_data$is_p20to40 == TRUE &
                                        temp_data$trial_type %in% c('choice', 'forced') &
                                        temp_data$option_choice == 2)
   # For each of the rare-outcome trials
   for(normal_count in seq(1,length(idx_chosen_normal_outcome))){
    # Get data slice
     temp = Windowrize(data = temp_data,
                       index_rare = idx_chosen_normal_outcome[normal_count],
                       window_size = 3)
     # Add count of the rare outcome
     temp$i_rare = normal_count
     # Fuse data for each participant & run
     window_data_normal = rbind(window_data_normal, temp)
   }
  }
}

window_data_normal$window_relative = as.numeric(as.character(window_data_normal$window_relative))
window_data_normal$window_relative = factor(window_data_normal$window_relative,
                                            levels = sort(unique(window_data_normal$window_relative)))

# Summarize data
window_data_run_normal = window_data_normal %>%
  # Eliminate windows which extended across trial boundaries (<1 or >240)
  .[, relative_trial := as.numeric(as.character(window_center)) + as.numeric(as.character(window_relative))] %>%
  .[!(relative_trial < 1 | relative_trial > 240),] %>%
  # Sort by relative window
  .[order(rank(group), rank(participant_id), rank(run), rank(window_relative)),] %>%
  # Get mean accuracy across all relative window positions (-2 to +3)
  .[, .(mean_accuracy = mean(correct_choice, na.rm = TRUE),
        n_data = sum(!is.na(correct_choice))),
    by = c('participant_id', 'group', 'run', 'window_relative')]

# Get mean across runs
window_data_participant_normal = window_data_run_normal %>%
  .[, .(accuracy = mean(mean_accuracy, na.rm = TRUE)),
    by = c('participant_id', 'group', 'window_relative')]
```

### Stats

```{r}
data_lme = window_data_run_normal[window_relative %in% c('-1', '1')] %>%
  .[, group := as.factor(group)] %>%
  .[, participant_id := as.factor(participant_id)]

lme = lme4::lmer(data = data_lme,
                 mean_accuracy ~ window_relative * group * run + (1 | participant_id))
Anova(lme)
```

#### Main effect run

```{r}
emmeans::emmeans(lme,
                 pairwise ~ run)
```

### Plot

```{r}
data_plot = Prepare_data_for_plot(window_data_participant_normal) %>%
  .[, window_relative := as.numeric(as.character(window_relative))] %>%
  .[!window_relative == 0, ]

data_plot_mean = data_plot %>%
  .[, .(accuracy = mean(accuracy),
        sem_accuracy = sd(accuracy) / sqrt(.N)),
    by = c('group', 'window_relative')]

dodge_width = 0.3

p = ggplot(data = data_plot,
       aes(x = window_relative,
           y = accuracy,
           fill = group,
           color = group,
           group = interaction(window_relative, group))) +
  geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = 0.1,
                                             jitter.height = 0,
                                             seed = 666),
             size = 0.5,
             alpha = 0.5) +
  # geom_line(aes(group = participant_id),
  #           alpha = 0.1,
  #           size = 0.5) +
  # geom_boxplot(color = 'black',
  #              outlier.shape = NA,
  #              width = dodge_width,
  #              position = position_dodge(width = dodge_width)) +
  geom_vline(xintercept = 0,
             linetype = 'dashed') +
  geom_path(data = data_plot_mean,
             size = 1,
             position = position_dodge(dodge_width),
            aes(group = group)) +
  geom_errorbar(data = data_plot_mean,
                  aes(x = window_relative,
                      y = accuracy,
                      ymin = accuracy - sem_accuracy,
                      ymax = accuracy + sem_accuracy),
                  size = 0.5,
                width = dodge_width/2,
                  position = position_dodge(dodge_width),
                color = 'black') +
  geom_point(data = data_plot_mean,
                  aes(x = window_relative,
                      y = accuracy),
                  size = 3,
                  position = position_dodge(dodge_width),
             shape = 21,
             color = 'black') +
  scale_fill_manual(values = custom_guides) +
  scale_color_manual(values = custom_guides) +
  scale_x_continuous(breaks = seq(min(data_plot$window_relative),
                                max(data_plot$window_relative))) +
  scale_y_continuous(limits = c(0,1)) +
  ggtext::geom_richtext(x = 0,
                        y = 0.1,
                        label = '20-40 percentile outcome in Mid arm',
                        fill = 'white',
                        color = 'black',
                        angle = 90,
                        size = 3,
                        hjust = 0) +
  labs(y = 'p(Choice Mid | LM)') +
  theme(legend.position = 'top')
  
Neurocodify_plot(p) +
  theme(panel.grid = element_blank())
```

---

## RT

```{r}
check_rt = data %>%
  .[, trial := seq(.N),
    by = c('participant_id', 'run')] %>%
  .[timeout == FALSE, ] %>%
  .[, log_rt := log(rt)] %>%
  data.table::melt(.,
                   id.vars = c('participant_id',
                               'group',
                               'run',
                               'trial',
                               'trial_type',
                               'comp'),
                   measure.vars = c('log_rt'))
```


### Comp resolves RT difference

```{r}
check_rt_mean = check_rt %>%
  .[variable == 'log_rt', ] %>%
  # Get mean log(rt) for each possible comparison
  .[, .(mean_value = mean(value)),
    by = c('participant_id', 'group', 'run', 'trial_type', 'comp')] %>%
  # Restrict to choice trials (ommitting forced choices)
  .[trial_type == 'choice',]
```

#### Stats

```{r}
# Assure data types
check_rt_mean$participant_id = as.factor(check_rt_mean$participant_id)
check_rt_mean$group = as.factor(check_rt_mean$group)
check_rt_mean$run = as.factor(check_rt_mean$run)
check_rt_mean$trial_type = as.factor(check_rt_mean$trial_type)
check_rt_mean$comp = as.factor(check_rt_mean$comp)
check_rt_mean$mean_value = as.numeric(check_rt_mean$mean_value)

lme_rt_comp = lme4::lmer(data = check_rt_mean,
                         mean_value ~ group * run * comp + (1|participant_id))
papeR::prettify(Anova(lme_rt_comp))
```

##### Main effect: Group

```{r}
emmeans::emmeans(lme_rt_comp,
                 pairwise ~ group)
```

##### Main effect: Comp

```{r}
emmeans::emmeans(lme_rt_comp,
                 pairwise ~ comp)
```

```{r}
emmeans::emmeans(lme_rt_comp,
                  pairwise ~ group * comp)
```


##### Interaction effect: Group x Comp

```{r}
emmeans::emmeans(lme_rt_comp,
                  pairwise ~ group | comp)
```


#### Plot

```{r}
data_plot = Prepare_data_for_plot(check_rt_mean)

dodge_width = 0.3

p_rt_comp = ggplot(data = data_plot,
       aes(x = comp,
           y = mean_value,
           color = group,
           fill = group)) +
  geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = dodge_width/2,
                                             jitter.height = 0,
                                             seed = 666)) +
  geom_boxplot(outlier.shape = NA,
               color = 'black',
               width = dodge_width,
               position = position_dodge(width = dodge_width)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = dodge_width),
               show.legend = FALSE) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides)
Neurocodify_plot(p_rt_comp)
  
```

Correlation RT to accuracy

---

# Estimation

Let running average not include first 10 trials or so

```{r}
# State melt columns (to align data types to avoid warnings)
measure_cols = c('est_1_reward',
                 'est_1_range',
                 'avg_1_running',
                 'est_2_reward',
                 'est_2_range',
                 'avg_2_running',
                 'est_3_reward',
                 'est_3_range',
                 'avg_3_running')

# Get estimation data
check_est = data %>%
  # Exclude: estimation specific
  Apply_exclusion_criteria(., choice_based_exclusion = FALSE) %>%
  # Get running average of chosen rewards
  .[, ':='(avg_1_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 1),
           avg_2_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 2),
           avg_3_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 3)),
    by = c('participant_id', 'run')] %>%
  .[, forced_rare := as.numeric(as.logical(is_rare) & trial_type == 'forced' & (comp == '1v2' | comp == '2v3'))] %>%
  .[!is.na(est_1_reward),] %>%
  .[, est_trial := seq(.N), by = c('participant_id', 'run')] %>%
  # Unify data types of measure columns
  .[, (measure_cols) := lapply(.SD, as.double), .SDcols = measure_cols] %>%
  data.table::melt(.,
                   id.vars = c('participant_id',
                               'group',
                               'run',
                               'est_trial',
                               'forced_rare'),
                   measure.vars = measure_cols) %>%
  .[, est_stim := substr(variable, 5, 5)] %>%
  .[, type := substr(variable, 7, 9)] %>%
  .[type == 'rew', type := 'reward'] %>%
  .[type == 'ran', type := 'range'] %>%
  .[type == 'run', type := 'r_avg'] %>%
  data.table::dcast(., participant_id + group + run + est_trial + forced_rare + est_stim ~ type,
                    value.var = 'value')

# Merge true means with estimation
check_est_diff = check_est %>%
  # Get difference between estimation and true mean
  .[, diff_from_true := reward - r_avg]

# Get mean estimation accuracy across estimation trials
check_mean_est_diff = check_est_diff %>%
  .[, half := rep(x = c(1,2), each = (max(est_trial)/2)),
    by = c('participant_id', 'group', 'run', 'est_stim')] %>%
  .[, .(mean_diff_from_true = mean(diff_from_true, na.rm = TRUE)),
    by = c('participant_id', 'group', 'run', 'half', 'est_stim')]
```

## Plot

```{r}
data_plot = Prepare_data_for_plot(check_mean_est_diff)

data_plot$half = as.factor(data_plot$half)
levels(data_plot$half) = c('First Half', 'Second Half')
data_plot$run = as.factor(data_plot$run)
levels(data_plot$run) = c('Run 1', 'Run 2')

p_check_mean_est_diff = ggplot(data = data_plot[half == 'Second Half'],
                               aes(x = est_stim,
                                   y = mean_diff_from_true,
                                   fill = group,
                                   color = group)) +
  geom_hline(yintercept = 0,
             size = 0.5) +
  geom_point(position = position_jitterdodge(dodge.width = 0.6,
                                             jitter.width = 0.2,
                                             jitter.height = 0)) +
  geom_boxplot(width = 0.5,
               color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = 0.6)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = 0.6),
               show.legend = FALSE)+
  scale_fill_manual(values = custom_guides) +
  scale_color_manual(values = custom_guides) +
  facet_grid(run ~ half)
Neurocodify_plot(p_check_mean_est_diff)
```


## Stats, Averaged over runs

```{r}
# Assure data types
check_mean_est_diff$participant_id = as.factor(check_mean_est_diff$participant_id)
check_mean_est_diff$group = as.factor(check_mean_est_diff$group)
check_mean_est_diff$run = as.factor(check_mean_est_diff$run)
check_mean_est_diff$est_stim = factor(check_mean_est_diff$est_stim)
levels(check_mean_est_diff$est_stim) = c('Low', 'Mid', 'High')
check_mean_est_diff$mean_diff_from_true = as.numeric(check_mean_est_diff$mean_diff_from_true)

#Only take second half (to allow learning)
check_mean_est_diff_half = check_mean_est_diff %>%
  .[half == '2',] %>%
  # Average over runs
  .[, .(mean_diff_from_true = mean(mean_diff_from_true)),
    by = c('participant_id', 'group', 'half', 'est_stim')]


# LME
lme_est_diff = lme4::lmer(data = check_mean_est_diff_half,
                          mean_diff_from_true ~ group * est_stim + (1 | participant_id))
papeR::prettify(Anova(lme_est_diff))
```

### Main effect: Stimulus

```{r}
emmeans::emmeans(lme_est_diff,
                 pairwise ~ est_stim)
```

```{r}
data_plot = Prepare_data_for_plot(check_mean_est_diff_half)

p_check_mean_est_diff = ggplot(data = data_plot[half == 2],
                               aes(x = est_stim,
                                   y = mean_diff_from_true,
                                   fill = est_stim,
                                   color = est_stim)) +
  geom_hline(yintercept = 0,
             size = 0.5) +
  geom_point(position = position_jitterdodge(dodge.width = 0.6,
                                             jitter.width = 0.2,
                                             jitter.height = 0)) +
  geom_boxplot(width = 0.5,
               color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = 0.6)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = 0.6),
               show.legend = FALSE)+
  scale_fill_manual(values = custom_guides) +
  scale_color_manual(values = custom_guides) +
  theme(legend.position = 'None')
Neurocodify_plot(p_check_mean_est_diff)
```

## Actually different from zero?

```{r}
data_test = check_mean_est_diff_half %>%
  # Test against 0
  .[, .(estimate = t.test(mean_diff_from_true, mu = 0)$estimate,
        t = t.test(mean_diff_from_true, mu = 0)$statistic,
        df = t.test(mean_diff_from_true, mu = 0)$parameter,
        p = t.test(mean_diff_from_true, mu = 0)$p.value),
    by = c('est_stim', 'group')]

knitr::kable(data_test) %>%
  kableExtra::kable_styling()

```

```{r}
data_plot = Prepare_data_for_plot(check_mean_est_diff_half)

p_check_mean_est_diff = ggplot(data = data_plot[half == 2],
                               aes(x = est_stim,
                                   y = mean_diff_from_true,
                                   fill = group,
                                   color = group,
                                   label = participant_id)) +
  geom_hline(yintercept = 0,
             size = 0.5) +
  geom_point(position = position_jitterdodge(dodge.width = 0.6,
                                             jitter.width = 0.2,
                                             jitter.height = 0)) +
  geom_boxplot(width = 0.5,
               color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = 0.6)) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               position = position_dodge(width = 0.6),
               show.legend = FALSE)+ 
  geom_text(size = 3,
             color = 'black') +
  scale_fill_manual(values = custom_guides) +
  scale_color_manual(values = custom_guides) +
  theme(legend.position = 'None')
Neurocodify_plot(p_check_mean_est_diff)
```


---

# Difference between real distance (running average) and estimated distance

```{r}
check_est_dist = data %>%
  # Exclude rating based
  Apply_exclusion_criteria(., choice_based_exclusion = FALSE) %>%
  # Get running average of chosen rewards
  .[, ':='(avg_1_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 1),
           avg_2_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 2),
           avg_3_running = Get_running_avg(choice_option = option_choice,
                                     choice_outcome = outcome,
                                     stim = 3)),
    by = c('participant_id', 'run')] %>%
  .[, forced_rare := as.numeric(as.logical(is_rare) & trial_type == 'forced' & (comp == '1v2' | comp == '2v3'))] %>%
  .[!is.na(est_1_reward),] %>%
  .[, est_trial := seq(.N), by = c('participant_id', 'run')] %>%
  # Unify data types of measure columns
  .[, (measure_cols) := lapply(.SD, as.double), .SDcols = measure_cols] %>%
  # Melt to change variable names of estimation variables
  data.table::melt(id.vars = c('participant_id',
                               'group',
                               'run',
                               'est_trial',
                               'forced_rare'),
                   measure.vars = measure_cols) %>%
  .[, est_stim := substr(variable, 5, 5)] %>%
  .[, type := substr(variable, 7, 9)] %>%
  .[type == 'rew', type := 'reward'] %>%
  .[type == 'ran', type := 'range'] %>%
  # Put back into long format to calculate distance between estimates
  data.table::dcast(., participant_id + group + run + est_trial + forced_rare ~ paste0(type, '_', est_stim),
                    value.var = 'value') %>%
  # Get distance between critical estimates
  .[, ':='(dist_est_2m1 = reward_2 - reward_1,
           dist_est_3m2 = reward_3 - reward_2)] %>%
  # Get difference of running averages of critical comparisons
  .[, ':='(dist_ravg_2m1 = run_2 - run_1,
           dist_ravg_3m2 = run_3 - run_2)] %>%
  # Add first and second half of run variable
  .[, half := rep(x = c(1,2), each = (max(est_trial)/2)),
    by = c('participant_id', 'group', 'run')] %>%
  .[, half := as.factor(half)] %>%
  # Get difference between real distance and estimated distance (Estimate - Real, EmR)
  .[, ':='(diff_EmR_2m1 = dist_est_2m1 - dist_ravg_2m1,
           diff_EmR_3m2 = dist_est_3m2 - dist_ravg_3m2)] %>%
  # Long format
  data.table::melt(id.vars = c('participant_id', 'group', 'run', 'half', 'est_trial'),
                   measure.vars = c('diff_EmR_2m1',
                                    'diff_EmR_3m2')) %>%
  # Average values
  .[, .(mean_value = mean(value, na.rm = TRUE)),
    by = c('participant_id', 'group', 'run', 'half', 'variable')]
  
```

## Stats

```{r}
# Assure data types
check_est_dist$participant_id = as.factor(check_est_dist$participant_id)
check_est_dist$group = as.factor(check_est_dist$group)
check_est_dist$run = as.factor(check_est_dist$run)
check_est_dist$half = as.factor(check_est_dist$half)
check_est_dist$variable = as.factor(check_est_dist$variable)
check_est_dist$mean_value = as.numeric(check_est_dist$mean_value)

lme_diff_EmR = lme4::lmer(data = check_est_dist,
                          mean_value ~ group * run * variable + (1 | participant_id))
papeR::prettify(Anova(lme_diff_EmR))
```

### Main effect: Variable

```{r}
emmeans::emmeans(lme_diff_EmR,
                 pairwise ~ variable)
```

### Interaction effect: Group X Variable

```{r}
emmeans::emmeans(lme_diff_EmR,
                 pairwise ~ variable | group)
```

## Plot

```{r}
data_plot = Prepare_data_for_plot(check_est_dist)

dodge_width = 0.2

p_diff_EmR = ggplot(data = data_plot,
       aes(x = variable,
           y = mean_value,
           color = group,
           fill = group)) +
  geom_hline(yintercept = 0,
             linetype = 'solid',
             size = 0.5) +
  geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = dodge_width/2,
                                             jitter.height = 0,
                                             seed = 666)) +
  geom_boxplot(color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = dodge_width),
               width = dodge_width) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               show.legend = FALSE,
               position = position_dodge(width = dodge_width)) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides)
Neurocodify_plot(p_diff_EmR)
  
```

```{r}
data_plot = Prepare_data_for_plot(check_est_dist)

dodge_width = 0.2

p_diff_EmR = ggplot(data = data_plot,
       aes(x = variable,
           y = mean_value,
           color = group,
           fill = group)) +
  geom_hline(yintercept = 0,
             linetype = 'solid',
             size = 0.5) +
  geom_point(position = position_jitterdodge(dodge.width = dodge_width,
                                             jitter.width = dodge_width/2,
                                             jitter.height = 0,
                                             seed = 666)) +
  geom_boxplot(color = 'black',
               outlier.shape = NA,
               position = position_dodge(width = dodge_width),
               width = dodge_width) +
  stat_summary(fun = 'mean',
               geom = 'point',
               na.rm = TRUE,
               shape = 23,
               inherit.aes = TRUE,
               fill = 'white',
               size = 1.5,
               stroke = 0.5,
               show.legend = FALSE,
               position = position_dodge(width = dodge_width)) +
  scale_color_manual(values = custom_guides) +
  scale_fill_manual(values = custom_guides) +
  facet_grid(~group)
Neurocodify_plot(p_diff_EmR)
  
```

---


